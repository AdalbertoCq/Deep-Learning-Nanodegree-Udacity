{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Prepare gym for agent\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Getting enviroment\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "[ 0.03058785 -0.15412635 -0.01584764  0.24713909]\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "env.reset()\n",
    "state, reward, done, info = env.step(env.action_space.sample())\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two possible actions [0,1]\n",
    "State descrived by [position of cart, velocity of cart, angle of pole, rotation rate of pole].\n",
    "\n",
    "Neural Network implementation to approximate the Q action value function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Experience Replay memory implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory_exp_replay:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def add_timestep(self, env_reaction):\n",
    "        # St, At, Rt1, St1.\n",
    "        self.buffer.append(env_reaction)\n",
    "        \n",
    "    def sample_random(self, sample_size, debug=False):\n",
    "        # Replace=False, important so it doesn't repeat a sample on the batch\n",
    "        indexs = np.random.choice(a=np.arange(len(self.buffer)), size=sample_size, replace=False) \n",
    "        if debug:\n",
    "            print(indexs)\n",
    "        states = list()\n",
    "        actions = list()\n",
    "        rewards = list()\n",
    "        next_states = list()\n",
    "        for index in indexs:\n",
    "            states.append(self.buffer[index][0])\n",
    "            actions.append(self.buffer[index][1])\n",
    "            rewards.append(self.buffer[index][2])\n",
    "            next_states.append(self.buffer[index][3])\n",
    "        batch = [np.array(states), np.array(actions), np.array(rewards), np.array(next_states)]\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out the Memory Buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order of enviroment reactions\n",
      "0 [ 0.00715869  0.01008044  0.04222421 -0.03998971]\n",
      "1 [ 0.0073603   0.20457226  0.04142442 -0.31905719]\n",
      "2 [ 0.01145174  0.39908051  0.03504327 -0.59839397]\n",
      "3 [ 0.01943335  0.59369506  0.02307539 -0.87983596]\n",
      "4 [ 0.03130725  0.39826733  0.00547867 -0.57998884]\n",
      "5 [ 0.0392726   0.59331208 -0.0061211  -0.87094085]\n",
      "6 [ 0.05113884  0.39827392 -0.02353992 -0.58018868]\n",
      "7 [ 0.05910432  0.20348961 -0.03514369 -0.29501326]\n",
      "8 [ 0.06317411  0.3990945  -0.04104396 -0.59856955]\n",
      "9 [ 0.071156    0.59476597 -0.05301535 -0.90389311]\n",
      "10 [ 0.08305132  0.79056435 -0.07109321 -1.21275724]\n",
      "11 [ 0.09886261  0.5964283  -0.09534836 -0.94317256]\n",
      "12 [ 0.11079117  0.79269662 -0.11421181 -1.26422777]\n",
      "13 [ 0.12664511  0.989078   -0.13949636 -1.590386  ]\n",
      "14 [ 0.14642667  0.795861   -0.17130408 -1.34425487]\n",
      "15 [ 0.16234389  0.99267292 -0.19818918 -1.68526917]\n",
      "16 [0. 0. 0. 0.]\n",
      "17 [ 0.03665265  0.17347703 -0.04523727 -0.33084363]\n",
      "18 [ 0.04012219  0.36921275 -0.05185414 -0.63744206]\n",
      "19 [ 0.04750645  0.17485079 -0.06460299 -0.36152928]\n",
      "Random sample from Memory Buffer\n",
      "[15  1]\n",
      "[ 0.16234389  0.99267292 -0.19818918 -1.68526917]\n",
      "[ 0.0073603   0.20457226  0.04142442 -0.31905719]\n"
     ]
    }
   ],
   "source": [
    "# Initliaze memory\n",
    "def populate_memory(env, exp_replay_memory, batch_size_Q, debug=False):\n",
    "    if debug: \n",
    "        print('Order of enviroment reactions')\n",
    "    content = 0\n",
    "    s_t1 = env.reset()\n",
    "    while content < batch_size_Q:\n",
    "        s_t = s_t1 \n",
    "        a_t = env.action_space.sample()\n",
    "        s_t1, r_t1, done, info = env.step(a_t)\n",
    "        if done:\n",
    "            s_t1 = np.zeros(s_t.shape)\n",
    "            if debug: \n",
    "                print(content, s_t)\n",
    "            exp_replay_memory.add_timestep((s_t, a_t, r_t1, s_t1))\n",
    "            s_t = env.reset()\n",
    "        else:\n",
    "            if debug: \n",
    "                print(content, s_t)\n",
    "            exp_replay_memory.add_timestep((s_t, a_t, r_t1, s_t1))\n",
    "        content += 1\n",
    "    return exp_replay_memory\n",
    "\n",
    "memory_size = 100000\n",
    "batch_size_Q = 20\n",
    "\n",
    "# Intantiate memory and populate\n",
    "exp_replay = Memory_exp_replay(memory_size)\n",
    "exp_replay = populate_memory(env, exp_replay, batch_size_Q, debug=True)\n",
    "\n",
    "print('Random sample from Memory Buffer')\n",
    "states, actions, rewards, next_states = exp_replay.sample_random(2, debug=True)\n",
    "for state in states:\n",
    "    print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory working well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Value Neural Network inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining NN for the action value function approximation.\n",
    "class NN_Q_approx:\n",
    "    def __init__(self, learning_rate, hidden_size, state_space, action_space, name):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.name = name\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.inputs = tf.placeholder(dtype=tf.float32, shape=[None, self.state_space], name='state_input')\n",
    "            \n",
    "            # Placeholder to choose the action value for the action done.\n",
    "            self.actions = tf.placeholder(dtype=tf.int32, shape=[None], name='action_output')\n",
    "            actions_oh = tf.one_hot(self.actions, self.action_space)\n",
    "            \n",
    "            self.target_Q = tf.placeholder(dtype=tf.float32, shape= [None], name='target_Q')\n",
    "            \n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs, hidden_size, scope='fc1')\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, 2*hidden_size, scope='fc2')\n",
    "            self.fc3 = tf.contrib.layers.fully_connected(self.fc2, hidden_size, scope='fc3')\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc3, self.action_space, activation_fn=None, scope='output')\n",
    "            # Until here for action value prediction.\n",
    "            \n",
    "            # Q size [m, action_space] -> sum, size [m, 1]\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, actions_oh), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.Q - self.target_Q))\n",
    "            self.opt = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)     \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining parameters for neural network and replay memory, to test out how NN performs to learn Q values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN parameters.\n",
    "learning_rate_nn = 0.0001\n",
    "hidden_size = 128\n",
    "state_space = len(state)\n",
    "action_space = env.action_space.n\n",
    "\n",
    "# Memory parameters.\n",
    "memory_size = 100000\n",
    "batch_size_Q = 32\n",
    "\n",
    "# Training parameters.\n",
    "max_episodes = 3000\n",
    "max_steps_episode = 200\n",
    "gamma = 1\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.05\n",
    "\n",
    "# Update Target NN weights every X steps.\n",
    "update_nn_target = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Epislon-Greedy Policy and Weigth update for the Target NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy(epsilon, q_value):\n",
    "    probabilities = np.ones(q_value[0].shape)*epsilon/action_space\n",
    "    probabilities[np.argmax(q_value[0])] = 1 - epsilon + (epsilon/action_space)\n",
    "    action = np.random.choice(a=np.arange(action_space), size=1, p=probabilities)\n",
    "    return int(action)\n",
    "\n",
    "\n",
    "# If I don't assign the value and variable relationship before each iteration, it is incredibly slow.\n",
    "# Assigning the relationship of the graph and just updating the value is much faster.\n",
    "def relate_variables_NN(Q_NN_target, Q_NN_grad):\n",
    "    assigns = list()\n",
    "    Q_NN_grad_variables =[v for v in tf.trainable_variables() if Q_NN_grad.name in v.name]\n",
    "    Q_NN_target_variables =[v for v in tf.trainable_variables() if Q_NN_target.name in v.name]\n",
    "#     Q_NN_grad_values = sess.run(Q_NN_grad_variables)\n",
    "    for ind_g, var in enumerate(Q_NN_grad_variables):\n",
    "        for var_target in Q_NN_target_variables:\n",
    "            if var_target.name.replace(Q_NN_target.name,Q_NN_grad.name)==var.name:\n",
    "#                 assigns.append(tf.assign(var_target, Q_NN_grad_values[ind_g]))\n",
    "                assigns.append(tf.assign(var_target, var.value()))\n",
    "                break\n",
    "\n",
    "    return assigns\n",
    "\n",
    "def update_values_sess(sess, assigns):\n",
    "    for assign_oper in assigns:\n",
    "        sess.run(assign_oper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to run training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 23.0000 Training loss: 1.0463 Epsilon: 0.9517\n",
      "Episode: 2 Total reward: 34.0000 Training loss: 1.1064 Epsilon: 0.9058\n",
      "Episode: 3 Total reward: 10.0000 Training loss: 1.0883 Epsilon: 0.8621\n",
      "Episode: 4 Total reward: 11.0000 Training loss: 1.3226 Epsilon: 0.8205\n",
      "Episode: 5 Total reward: 14.0000 Training loss: 1.6325 Epsilon: 0.7810\n",
      "Episode: 6 Total reward: 19.0000 Training loss: 1.7054 Epsilon: 0.7434\n",
      "Episode: 7 Total reward: 13.0000 Training loss: 2.0638 Epsilon: 0.7076\n",
      "Episode: 8 Total reward: 20.0000 Training loss: 4.1626 Epsilon: 0.6736\n",
      "Episode: 9 Total reward: 20.0000 Training loss: 4.3508 Epsilon: 0.6413\n",
      "Episode: 10 Total reward: 30.0000 Training loss: 19.1005 Epsilon: 0.6105\n",
      "Episode: 11 Total reward: 14.0000 Training loss: 16.1310 Epsilon: 0.5812\n",
      "Episode: 12 Total reward: 10.0000 Training loss: 11.4382 Epsilon: 0.5533\n",
      "Episode: 13 Total reward: 25.0000 Training loss: 95.2894 Epsilon: 0.5268\n",
      "Episode: 14 Total reward: 12.0000 Training loss: 49.1709 Epsilon: 0.5016\n",
      "Episode: 15 Total reward: 10.0000 Training loss: 164.7706 Epsilon: 0.4776\n",
      "Episode: 16 Total reward: 17.0000 Training loss: 50.4484 Epsilon: 0.4548\n",
      "Episode: 17 Total reward: 13.0000 Training loss: 229.4877 Epsilon: 0.4331\n",
      "Episode: 18 Total reward: 14.0000 Training loss: 179.8755 Epsilon: 0.4125\n",
      "Episode: 19 Total reward: 21.0000 Training loss: 336.0696 Epsilon: 0.3929\n",
      "Episode: 20 Total reward: 11.0000 Training loss: 52.9770 Epsilon: 0.3742\n",
      "Episode: 21 Total reward: 10.0000 Training loss: 171.4472 Epsilon: 0.3564\n",
      "Episode: 22 Total reward: 11.0000 Training loss: 44.5805 Epsilon: 0.3395\n",
      "Episode: 23 Total reward: 13.0000 Training loss: 242.3829 Epsilon: 0.3235\n",
      "Episode: 24 Total reward: 10.0000 Training loss: 249.0803 Epsilon: 0.3082\n",
      "Episode: 25 Total reward: 9.0000 Training loss: 272.9352 Epsilon: 0.2936\n",
      "Episode: 26 Total reward: 9.0000 Training loss: 328.5705 Epsilon: 0.2798\n",
      "Episode: 27 Total reward: 8.0000 Training loss: 35.9995 Epsilon: 0.2666\n",
      "Episode: 28 Total reward: 10.0000 Training loss: 156.7125 Epsilon: 0.2541\n",
      "Episode: 29 Total reward: 11.0000 Training loss: 313.2372 Epsilon: 0.2422\n",
      "Episode: 30 Total reward: 9.0000 Training loss: 294.0410 Epsilon: 0.2309\n",
      "Episode: 31 Total reward: 11.0000 Training loss: 241.8586 Epsilon: 0.2201\n",
      "Episode: 32 Total reward: 11.0000 Training loss: 252.9182 Epsilon: 0.2099\n",
      "Episode: 33 Total reward: 10.0000 Training loss: 39.4606 Epsilon: 0.2001\n",
      "Episode: 34 Total reward: 9.0000 Training loss: 371.5759 Epsilon: 0.1909\n",
      "Episode: 35 Total reward: 9.0000 Training loss: 62.8853 Epsilon: 0.1820\n",
      "Episode: 36 Total reward: 9.0000 Training loss: 262.9345 Epsilon: 0.1736\n",
      "Episode: 37 Total reward: 10.0000 Training loss: 305.9294 Epsilon: 0.1657\n",
      "Episode: 38 Total reward: 10.0000 Training loss: 121.3537 Epsilon: 0.1581\n",
      "Episode: 39 Total reward: 10.0000 Training loss: 194.2834 Epsilon: 0.1509\n",
      "Episode: 40 Total reward: 9.0000 Training loss: 177.7938 Epsilon: 0.1440\n",
      "Episode: 41 Total reward: 10.0000 Training loss: 337.2508 Epsilon: 0.1374\n",
      "Episode: 42 Total reward: 12.0000 Training loss: 221.5099 Epsilon: 0.1312\n",
      "Episode: 43 Total reward: 10.0000 Training loss: 114.0837 Epsilon: 0.1253\n",
      "Episode: 44 Total reward: 12.0000 Training loss: 326.2983 Epsilon: 0.1197\n",
      "Episode: 45 Total reward: 9.0000 Training loss: 400.4544 Epsilon: 0.1143\n",
      "Episode: 46 Total reward: 10.0000 Training loss: 64.4647 Epsilon: 0.1093\n",
      "Episode: 47 Total reward: 10.0000 Training loss: 408.4788 Epsilon: 0.1044\n",
      "Episode: 48 Total reward: 9.0000 Training loss: 387.7330 Epsilon: 0.0998\n",
      "Episode: 49 Total reward: 10.0000 Training loss: 16.4705 Epsilon: 0.0954\n",
      "Episode: 50 Total reward: 9.0000 Training loss: 62.5268 Epsilon: 0.0913\n",
      "Episode: 51 Total reward: 9.0000 Training loss: 396.7072 Epsilon: 0.0873\n",
      "Episode: 52 Total reward: 12.0000 Training loss: 317.0584 Epsilon: 0.0835\n",
      "Episode: 53 Total reward: 10.0000 Training loss: 476.9710 Epsilon: 0.0799\n",
      "Episode: 54 Total reward: 9.0000 Training loss: 351.2703 Epsilon: 0.0765\n",
      "Episode: 55 Total reward: 9.0000 Training loss: 35.0001 Epsilon: 0.0733\n",
      "Episode: 56 Total reward: 8.0000 Training loss: 33.9472 Epsilon: 0.0702\n",
      "Episode: 57 Total reward: 10.0000 Training loss: 92.9805 Epsilon: 0.0673\n",
      "Episode: 58 Total reward: 11.0000 Training loss: 204.3369 Epsilon: 0.0645\n",
      "Episode: 59 Total reward: 9.0000 Training loss: 50.9954 Epsilon: 0.0618\n",
      "Episode: 60 Total reward: 10.0000 Training loss: 10.5489 Epsilon: 0.0593\n",
      "Episode: 61 Total reward: 9.0000 Training loss: 40.0755 Epsilon: 0.0569\n",
      "Episode: 62 Total reward: 10.0000 Training loss: 29.3152 Epsilon: 0.0546\n",
      "Episode: 63 Total reward: 10.0000 Training loss: 106.5600 Epsilon: 0.0524\n",
      "Episode: 64 Total reward: 10.0000 Training loss: 123.8679 Epsilon: 0.0504\n",
      "Episode: 65 Total reward: 9.0000 Training loss: 218.9395 Epsilon: 0.0484\n",
      "Episode: 66 Total reward: 10.0000 Training loss: 102.4107 Epsilon: 0.0465\n",
      "Episode: 67 Total reward: 10.0000 Training loss: 25.6494 Epsilon: 0.0447\n",
      "Episode: 68 Total reward: 10.0000 Training loss: 244.6258 Epsilon: 0.0430\n",
      "Episode: 69 Total reward: 10.0000 Training loss: 17.8358 Epsilon: 0.0414\n",
      "Episode: 70 Total reward: 9.0000 Training loss: 94.0354 Epsilon: 0.0399\n",
      "Episode: 71 Total reward: 9.0000 Training loss: 91.3841 Epsilon: 0.0384\n",
      "Episode: 72 Total reward: 9.0000 Training loss: 67.8450 Epsilon: 0.0371\n",
      "Episode: 73 Total reward: 10.0000 Training loss: 20.5776 Epsilon: 0.0357\n",
      "Episode: 74 Total reward: 8.0000 Training loss: 126.7823 Epsilon: 0.0345\n",
      "Episode: 75 Total reward: 9.0000 Training loss: 36.4426 Epsilon: 0.0333\n",
      "Episode: 76 Total reward: 9.0000 Training loss: 33.4366 Epsilon: 0.0321\n",
      "Episode: 77 Total reward: 10.0000 Training loss: 66.3265 Epsilon: 0.0311\n",
      "Episode: 78 Total reward: 9.0000 Training loss: 21.9656 Epsilon: 0.0300\n",
      "Episode: 79 Total reward: 12.0000 Training loss: 29.5681 Epsilon: 0.0291\n",
      "Episode: 80 Total reward: 25.0000 Training loss: 9.2358 Epsilon: 0.0281\n",
      "Episode: 81 Total reward: 10.0000 Training loss: 41.5419 Epsilon: 0.0272\n",
      "Episode: 82 Total reward: 10.0000 Training loss: 8.6908 Epsilon: 0.0264\n",
      "Episode: 83 Total reward: 9.0000 Training loss: 51.3263 Epsilon: 0.0256\n",
      "Episode: 84 Total reward: 10.0000 Training loss: 77.1237 Epsilon: 0.0248\n",
      "Episode: 85 Total reward: 9.0000 Training loss: 63.2427 Epsilon: 0.0241\n",
      "Episode: 86 Total reward: 9.0000 Training loss: 7.1413 Epsilon: 0.0234\n",
      "Episode: 87 Total reward: 9.0000 Training loss: 87.9321 Epsilon: 0.0228\n",
      "Episode: 88 Total reward: 9.0000 Training loss: 111.8671 Epsilon: 0.0222\n",
      "Episode: 89 Total reward: 10.0000 Training loss: 35.3837 Epsilon: 0.0216\n",
      "Episode: 90 Total reward: 10.0000 Training loss: 7.9019 Epsilon: 0.0210\n",
      "Episode: 91 Total reward: 36.0000 Training loss: 33.6625 Epsilon: 0.0205\n",
      "Episode: 92 Total reward: 24.0000 Training loss: 3.9690 Epsilon: 0.0200\n",
      "Episode: 93 Total reward: 20.0000 Training loss: 34.0522 Epsilon: 0.0195\n",
      "Episode: 94 Total reward: 25.0000 Training loss: 29.1664 Epsilon: 0.0190\n",
      "Episode: 95 Total reward: 24.0000 Training loss: 28.7198 Epsilon: 0.0186\n",
      "Episode: 96 Total reward: 19.0000 Training loss: 22.6007 Epsilon: 0.0181\n",
      "Episode: 97 Total reward: 21.0000 Training loss: 15.9817 Epsilon: 0.0178\n",
      "Episode: 98 Total reward: 22.0000 Training loss: 7.5516 Epsilon: 0.0174\n",
      "Episode: 99 Total reward: 47.0000 Training loss: 20.8353 Epsilon: 0.0170\n",
      "Episode: 100 Total reward: 70.0000 Training loss: 36.7333 Epsilon: 0.0167\n",
      "Episode: 101 Total reward: 45.0000 Training loss: 21.0001 Epsilon: 0.0163\n",
      "Episode: 102 Total reward: 74.0000 Training loss: 3.7606 Epsilon: 0.0160\n",
      "Episode: 103 Total reward: 69.0000 Training loss: 39.6363 Epsilon: 0.0157\n",
      "Episode: 104 Total reward: 49.0000 Training loss: 10.0915 Epsilon: 0.0155\n",
      "Episode: 105 Total reward: 58.0000 Training loss: 21.5824 Epsilon: 0.0152\n",
      "Episode: 106 Total reward: 107.0000 Training loss: 48.5975 Epsilon: 0.0149\n",
      "Episode: 107 Total reward: 69.0000 Training loss: 42.8648 Epsilon: 0.0147\n",
      "Episode: 108 Total reward: 67.0000 Training loss: 32.1404 Epsilon: 0.0145\n",
      "Episode: 109 Total reward: 91.0000 Training loss: 5.9944 Epsilon: 0.0143\n",
      "Episode: 110 Total reward: 86.0000 Training loss: 4.7348 Epsilon: 0.0140\n",
      "Episode: 111 Total reward: 26.0000 Training loss: 32.8098 Epsilon: 0.0138\n",
      "Episode: 112 Total reward: 28.0000 Training loss: 59.3233 Epsilon: 0.0137\n",
      "Episode: 113 Total reward: 28.0000 Training loss: 64.9885 Epsilon: 0.0135\n",
      "Episode: 114 Total reward: 18.0000 Training loss: 73.0104 Epsilon: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 115 Total reward: 22.0000 Training loss: 42.9857 Epsilon: 0.0132\n",
      "Episode: 116 Total reward: 20.0000 Training loss: 174.5143 Epsilon: 0.0130\n",
      "Episode: 117 Total reward: 22.0000 Training loss: 74.6349 Epsilon: 0.0129\n",
      "Episode: 118 Total reward: 19.0000 Training loss: 23.9269 Epsilon: 0.0127\n",
      "Episode: 119 Total reward: 21.0000 Training loss: 44.5627 Epsilon: 0.0126\n",
      "Episode: 120 Total reward: 20.0000 Training loss: 132.4337 Epsilon: 0.0125\n",
      "Episode: 121 Total reward: 25.0000 Training loss: 11.5140 Epsilon: 0.0123\n",
      "Episode: 122 Total reward: 32.0000 Training loss: 122.9443 Epsilon: 0.0122\n",
      "Episode: 123 Total reward: 19.0000 Training loss: 93.0540 Epsilon: 0.0121\n",
      "Episode: 124 Total reward: 41.0000 Training loss: 30.7778 Epsilon: 0.0120\n",
      "Episode: 125 Total reward: 40.0000 Training loss: 61.7643 Epsilon: 0.0119\n",
      "Episode: 126 Total reward: 31.0000 Training loss: 5.9118 Epsilon: 0.0118\n",
      "Episode: 127 Total reward: 41.0000 Training loss: 186.3863 Epsilon: 0.0117\n",
      "Episode: 128 Total reward: 32.0000 Training loss: 38.8653 Epsilon: 0.0116\n",
      "Episode: 129 Total reward: 39.0000 Training loss: 20.8129 Epsilon: 0.0116\n",
      "Episode: 130 Total reward: 44.0000 Training loss: 7.3645 Epsilon: 0.0115\n",
      "Episode: 131 Total reward: 31.0000 Training loss: 9.1464 Epsilon: 0.0114\n",
      "Episode: 132 Total reward: 23.0000 Training loss: 126.7738 Epsilon: 0.0113\n",
      "Episode: 133 Total reward: 25.0000 Training loss: 4.2150 Epsilon: 0.0113\n",
      "Episode: 134 Total reward: 20.0000 Training loss: 85.0394 Epsilon: 0.0112\n",
      "Episode: 135 Total reward: 38.0000 Training loss: 6.7882 Epsilon: 0.0112\n",
      "Episode: 136 Total reward: 52.0000 Training loss: 27.8945 Epsilon: 0.0111\n",
      "Episode: 137 Total reward: 48.0000 Training loss: 191.2723 Epsilon: 0.0110\n",
      "Episode: 138 Total reward: 50.0000 Training loss: 170.0013 Epsilon: 0.0110\n",
      "Episode: 139 Total reward: 74.0000 Training loss: 73.4753 Epsilon: 0.0109\n",
      "Episode: 140 Total reward: 72.0000 Training loss: 11.3079 Epsilon: 0.0109\n",
      "Episode: 141 Total reward: 39.0000 Training loss: 60.1261 Epsilon: 0.0109\n",
      "Episode: 142 Total reward: 45.0000 Training loss: 139.5109 Epsilon: 0.0108\n",
      "Episode: 143 Total reward: 174.0000 Training loss: 16.8545 Epsilon: 0.0108\n",
      "Episode: 144 Total reward: 40.0000 Training loss: 43.1008 Epsilon: 0.0107\n",
      "Episode: 145 Total reward: 73.0000 Training loss: 55.1822 Epsilon: 0.0107\n",
      "Episode: 146 Total reward: 25.0000 Training loss: 199.9632 Epsilon: 0.0107\n",
      "Episode: 147 Total reward: 157.0000 Training loss: 7.7709 Epsilon: 0.0106\n",
      "Episode: 148 Total reward: 62.0000 Training loss: 8.6649 Epsilon: 0.0106\n",
      "Episode: 149 Total reward: 53.0000 Training loss: 102.0599 Epsilon: 0.0106\n",
      "Episode: 150 Total reward: 42.0000 Training loss: 16.4656 Epsilon: 0.0105\n",
      "Episode: 151 Total reward: 31.0000 Training loss: 7.2416 Epsilon: 0.0105\n",
      "Episode: 152 Total reward: 127.0000 Training loss: 34.4230 Epsilon: 0.0105\n",
      "Episode: 153 Total reward: 43.0000 Training loss: 193.7614 Epsilon: 0.0105\n",
      "Episode: 154 Total reward: 53.0000 Training loss: 51.2445 Epsilon: 0.0104\n",
      "Episode: 155 Total reward: 53.0000 Training loss: 7.2025 Epsilon: 0.0104\n",
      "Episode: 156 Total reward: 69.0000 Training loss: 266.8193 Epsilon: 0.0104\n",
      "Episode: 157 Total reward: 72.0000 Training loss: 24.8166 Epsilon: 0.0104\n",
      "Episode: 158 Total reward: 57.0000 Training loss: 7.5291 Epsilon: 0.0104\n",
      "Episode: 159 Total reward: 53.0000 Training loss: 6.4941 Epsilon: 0.0103\n",
      "Episode: 160 Total reward: 71.0000 Training loss: 237.7282 Epsilon: 0.0103\n",
      "Episode: 161 Total reward: 89.0000 Training loss: 7.3693 Epsilon: 0.0103\n",
      "Episode: 162 Total reward: 62.0000 Training loss: 400.7868 Epsilon: 0.0103\n",
      "Episode: 163 Total reward: 122.0000 Training loss: 9.5711 Epsilon: 0.0103\n",
      "Episode: 164 Total reward: 124.0000 Training loss: 18.0532 Epsilon: 0.0103\n",
      "Episode: 165 Total reward: 51.0000 Training loss: 32.2948 Epsilon: 0.0103\n",
      "Episode: 166 Total reward: 83.0000 Training loss: 12.5347 Epsilon: 0.0102\n",
      "Episode: 167 Total reward: 84.0000 Training loss: 1.8846 Epsilon: 0.0102\n",
      "Episode: 168 Total reward: 103.0000 Training loss: 17.2258 Epsilon: 0.0102\n",
      "Episode: 169 Total reward: 94.0000 Training loss: 33.1724 Epsilon: 0.0102\n",
      "Episode: 170 Total reward: 57.0000 Training loss: 10.3603 Epsilon: 0.0102\n",
      "Episode: 171 Total reward: 80.0000 Training loss: 356.5244 Epsilon: 0.0102\n",
      "Episode: 172 Total reward: 148.0000 Training loss: 6.4583 Epsilon: 0.0102\n",
      "Episode: 173 Total reward: 79.0000 Training loss: 97.4098 Epsilon: 0.0102\n",
      "Episode: 174 Total reward: 172.0000 Training loss: 4.6360 Epsilon: 0.0102\n",
      "Episode: 175 Total reward: 200.0000 Training loss: 25.9892 Epsilon: 0.0102\n",
      "Episode: 176 Total reward: 166.0000 Training loss: 116.2641 Epsilon: 0.0101\n",
      "Episode: 177 Total reward: 163.0000 Training loss: 26.6115 Epsilon: 0.0101\n",
      "Episode: 178 Total reward: 200.0000 Training loss: 6.9275 Epsilon: 0.0101\n",
      "Episode: 179 Total reward: 101.0000 Training loss: 4.3441 Epsilon: 0.0101\n",
      "Episode: 180 Total reward: 200.0000 Training loss: 408.5200 Epsilon: 0.0101\n",
      "Episode: 181 Total reward: 82.0000 Training loss: 39.6850 Epsilon: 0.0101\n",
      "Episode: 182 Total reward: 149.0000 Training loss: 3.8638 Epsilon: 0.0101\n",
      "Episode: 183 Total reward: 151.0000 Training loss: 125.0808 Epsilon: 0.0101\n",
      "Episode: 184 Total reward: 154.0000 Training loss: 7.5260 Epsilon: 0.0101\n",
      "Episode: 185 Total reward: 182.0000 Training loss: 7.0983 Epsilon: 0.0101\n",
      "Episode: 186 Total reward: 124.0000 Training loss: 9.5623 Epsilon: 0.0101\n",
      "Episode: 187 Total reward: 169.0000 Training loss: 200.1810 Epsilon: 0.0101\n",
      "Episode: 188 Total reward: 120.0000 Training loss: 16.9376 Epsilon: 0.0101\n",
      "Episode: 189 Total reward: 138.0000 Training loss: 63.4062 Epsilon: 0.0101\n",
      "Episode: 190 Total reward: 174.0000 Training loss: 5.5971 Epsilon: 0.0101\n",
      "Episode: 191 Total reward: 138.0000 Training loss: 41.2332 Epsilon: 0.0101\n",
      "Episode: 192 Total reward: 129.0000 Training loss: 8.1724 Epsilon: 0.0101\n",
      "Episode: 193 Total reward: 142.0000 Training loss: 14.4646 Epsilon: 0.0101\n",
      "Episode: 194 Total reward: 154.0000 Training loss: 3.3962 Epsilon: 0.0101\n",
      "Episode: 195 Total reward: 133.0000 Training loss: 37.1823 Epsilon: 0.0101\n",
      "Episode: 196 Total reward: 136.0000 Training loss: 274.1809 Epsilon: 0.0101\n",
      "Episode: 197 Total reward: 135.0000 Training loss: 28.4797 Epsilon: 0.0101\n",
      "Episode: 198 Total reward: 145.0000 Training loss: 36.7690 Epsilon: 0.0100\n",
      "Episode: 199 Total reward: 122.0000 Training loss: 46.4661 Epsilon: 0.0100\n",
      "Episode: 200 Total reward: 139.0000 Training loss: 5.9978 Epsilon: 0.0100\n",
      "Episode: 201 Total reward: 148.0000 Training loss: 210.2388 Epsilon: 0.0100\n",
      "Episode: 202 Total reward: 126.0000 Training loss: 32.4519 Epsilon: 0.0100\n",
      "Episode: 203 Total reward: 120.0000 Training loss: 19.7121 Epsilon: 0.0100\n",
      "Episode: 204 Total reward: 200.0000 Training loss: 13.5462 Epsilon: 0.0100\n",
      "Episode: 205 Total reward: 176.0000 Training loss: 25.7098 Epsilon: 0.0100\n",
      "Episode: 206 Total reward: 152.0000 Training loss: 25.8856 Epsilon: 0.0100\n",
      "Episode: 207 Total reward: 200.0000 Training loss: 14.7087 Epsilon: 0.0100\n",
      "Episode: 208 Total reward: 140.0000 Training loss: 227.4441 Epsilon: 0.0100\n",
      "Episode: 209 Total reward: 166.0000 Training loss: 21.9311 Epsilon: 0.0100\n",
      "Episode: 210 Total reward: 129.0000 Training loss: 1763.2585 Epsilon: 0.0100\n",
      "Episode: 211 Total reward: 131.0000 Training loss: 25.3558 Epsilon: 0.0100\n",
      "Episode: 212 Total reward: 162.0000 Training loss: 218.7934 Epsilon: 0.0100\n",
      "Episode: 213 Total reward: 180.0000 Training loss: 36.2115 Epsilon: 0.0100\n",
      "Episode: 214 Total reward: 172.0000 Training loss: 16.4424 Epsilon: 0.0100\n",
      "Episode: 215 Total reward: 142.0000 Training loss: 37.9642 Epsilon: 0.0100\n",
      "Episode: 216 Total reward: 134.0000 Training loss: 13.8544 Epsilon: 0.0100\n",
      "Episode: 217 Total reward: 130.0000 Training loss: 22.8838 Epsilon: 0.0100\n",
      "Episode: 218 Total reward: 197.0000 Training loss: 17.8986 Epsilon: 0.0100\n",
      "Episode: 219 Total reward: 144.0000 Training loss: 17.1240 Epsilon: 0.0100\n",
      "Episode: 220 Total reward: 200.0000 Training loss: 346.5567 Epsilon: 0.0100\n",
      "Episode: 221 Total reward: 192.0000 Training loss: 21.3970 Epsilon: 0.0100\n",
      "Episode: 222 Total reward: 200.0000 Training loss: 7.8710 Epsilon: 0.0100\n",
      "Episode: 223 Total reward: 200.0000 Training loss: 28.7489 Epsilon: 0.0100\n",
      "Episode: 224 Total reward: 200.0000 Training loss: 13.0185 Epsilon: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 225 Total reward: 200.0000 Training loss: 56.9422 Epsilon: 0.0100\n",
      "Episode: 226 Total reward: 173.0000 Training loss: 16.8076 Epsilon: 0.0100\n",
      "Episode: 227 Total reward: 200.0000 Training loss: 196.7849 Epsilon: 0.0100\n",
      "Episode: 228 Total reward: 200.0000 Training loss: 29.4141 Epsilon: 0.0100\n",
      "Episode: 229 Total reward: 200.0000 Training loss: 810.8082 Epsilon: 0.0100\n",
      "Episode: 230 Total reward: 200.0000 Training loss: 39.4788 Epsilon: 0.0100\n",
      "Episode: 231 Total reward: 200.0000 Training loss: 113.5783 Epsilon: 0.0100\n",
      "Episode: 232 Total reward: 200.0000 Training loss: 4513.6152 Epsilon: 0.0100\n",
      "Episode: 233 Total reward: 200.0000 Training loss: 159.0254 Epsilon: 0.0100\n",
      "Episode: 234 Total reward: 200.0000 Training loss: 151.3783 Epsilon: 0.0100\n",
      "Episode: 235 Total reward: 200.0000 Training loss: 94.9043 Epsilon: 0.0100\n",
      "Episode: 236 Total reward: 200.0000 Training loss: 5058.7046 Epsilon: 0.0100\n",
      "Episode: 237 Total reward: 200.0000 Training loss: 6178.4131 Epsilon: 0.0100\n",
      "Episode: 238 Total reward: 200.0000 Training loss: 322.9465 Epsilon: 0.0100\n",
      "Episode: 239 Total reward: 200.0000 Training loss: 192.5553 Epsilon: 0.0100\n",
      "Episode: 240 Total reward: 200.0000 Training loss: 229.0240 Epsilon: 0.0100\n",
      "Episode: 241 Total reward: 200.0000 Training loss: 309.4470 Epsilon: 0.0100\n",
      "Episode: 242 Total reward: 200.0000 Training loss: 25287.7598 Epsilon: 0.0100\n",
      "Episode: 243 Total reward: 200.0000 Training loss: 119.5844 Epsilon: 0.0100\n",
      "Episode: 244 Total reward: 200.0000 Training loss: 277.5404 Epsilon: 0.0100\n",
      "Episode: 245 Total reward: 200.0000 Training loss: 8523.3994 Epsilon: 0.0100\n",
      "Episode: 246 Total reward: 200.0000 Training loss: 94.3079 Epsilon: 0.0100\n",
      "Episode: 247 Total reward: 200.0000 Training loss: 6075.9312 Epsilon: 0.0100\n",
      "Episode: 248 Total reward: 200.0000 Training loss: 265.0949 Epsilon: 0.0100\n",
      "Episode: 249 Total reward: 200.0000 Training loss: 474.7970 Epsilon: 0.0100\n",
      "Episode: 250 Total reward: 200.0000 Training loss: 17695.8516 Epsilon: 0.0100\n",
      "Episode: 251 Total reward: 200.0000 Training loss: 470.6472 Epsilon: 0.0100\n",
      "Episode: 252 Total reward: 200.0000 Training loss: 24847.0703 Epsilon: 0.0100\n",
      "Episode: 253 Total reward: 200.0000 Training loss: 7839.7002 Epsilon: 0.0100\n",
      "Episode: 254 Total reward: 200.0000 Training loss: 226.8647 Epsilon: 0.0100\n",
      "Episode: 255 Total reward: 200.0000 Training loss: 622.5525 Epsilon: 0.0100\n",
      "Episode: 256 Total reward: 197.0000 Training loss: 191.4001 Epsilon: 0.0100\n",
      "Episode: 257 Total reward: 200.0000 Training loss: 159.7350 Epsilon: 0.0100\n",
      "Episode: 258 Total reward: 200.0000 Training loss: 212.8985 Epsilon: 0.0100\n",
      "Episode: 259 Total reward: 176.0000 Training loss: 151.8750 Epsilon: 0.0100\n",
      "Episode: 260 Total reward: 200.0000 Training loss: 381.2410 Epsilon: 0.0100\n",
      "Episode: 261 Total reward: 200.0000 Training loss: 260.4617 Epsilon: 0.0100\n",
      "Episode: 262 Total reward: 200.0000 Training loss: 184.7890 Epsilon: 0.0100\n",
      "Episode: 263 Total reward: 200.0000 Training loss: 397.4901 Epsilon: 0.0100\n",
      "Episode: 264 Total reward: 200.0000 Training loss: 176.2665 Epsilon: 0.0100\n",
      "Episode: 265 Total reward: 200.0000 Training loss: 501.3654 Epsilon: 0.0100\n",
      "Episode: 266 Total reward: 200.0000 Training loss: 85.5137 Epsilon: 0.0100\n",
      "Episode: 267 Total reward: 200.0000 Training loss: 176.0817 Epsilon: 0.0100\n",
      "Episode: 268 Total reward: 200.0000 Training loss: 275.8092 Epsilon: 0.0100\n",
      "Episode: 269 Total reward: 200.0000 Training loss: 204.2533 Epsilon: 0.0100\n",
      "Episode: 270 Total reward: 200.0000 Training loss: 162.3195 Epsilon: 0.0100\n",
      "Episode: 271 Total reward: 200.0000 Training loss: 3752.5869 Epsilon: 0.0100\n",
      "Episode: 272 Total reward: 200.0000 Training loss: 118.0280 Epsilon: 0.0100\n",
      "Episode: 273 Total reward: 200.0000 Training loss: 119.4975 Epsilon: 0.0100\n",
      "Episode: 274 Total reward: 200.0000 Training loss: 7917.3745 Epsilon: 0.0100\n",
      "Episode: 275 Total reward: 200.0000 Training loss: 112.4879 Epsilon: 0.0100\n",
      "Episode: 276 Total reward: 200.0000 Training loss: 23556.8945 Epsilon: 0.0100\n",
      "Episode: 277 Total reward: 200.0000 Training loss: 163.5614 Epsilon: 0.0100\n",
      "Episode: 278 Total reward: 152.0000 Training loss: 122.4635 Epsilon: 0.0100\n",
      "Episode: 279 Total reward: 157.0000 Training loss: 356.4911 Epsilon: 0.0100\n",
      "Episode: 280 Total reward: 200.0000 Training loss: 1673.9832 Epsilon: 0.0100\n",
      "Episode: 281 Total reward: 200.0000 Training loss: 77.9354 Epsilon: 0.0100\n",
      "Episode: 282 Total reward: 162.0000 Training loss: 83.8261 Epsilon: 0.0100\n",
      "Episode: 283 Total reward: 200.0000 Training loss: 75.2212 Epsilon: 0.0100\n",
      "Episode: 284 Total reward: 176.0000 Training loss: 296.2429 Epsilon: 0.0100\n",
      "Episode: 285 Total reward: 200.0000 Training loss: 162.6386 Epsilon: 0.0100\n",
      "Episode: 286 Total reward: 182.0000 Training loss: 214.6283 Epsilon: 0.0100\n",
      "Episode: 287 Total reward: 185.0000 Training loss: 225.7073 Epsilon: 0.0100\n",
      "Episode: 288 Total reward: 200.0000 Training loss: 90.9621 Epsilon: 0.0100\n",
      "Episode: 289 Total reward: 200.0000 Training loss: 102.6708 Epsilon: 0.0100\n",
      "Episode: 290 Total reward: 200.0000 Training loss: 1290.1315 Epsilon: 0.0100\n",
      "Episode: 291 Total reward: 200.0000 Training loss: 163.0383 Epsilon: 0.0100\n",
      "Episode: 292 Total reward: 200.0000 Training loss: 224.1820 Epsilon: 0.0100\n",
      "Episode: 293 Total reward: 200.0000 Training loss: 49.9253 Epsilon: 0.0100\n",
      "Episode: 294 Total reward: 178.0000 Training loss: 987.2634 Epsilon: 0.0100\n",
      "Episode: 295 Total reward: 200.0000 Training loss: 54.8444 Epsilon: 0.0100\n",
      "Episode: 296 Total reward: 200.0000 Training loss: 213.8194 Epsilon: 0.0100\n",
      "Episode: 297 Total reward: 200.0000 Training loss: 91.9099 Epsilon: 0.0100\n",
      "Episode: 298 Total reward: 200.0000 Training loss: 202.5240 Epsilon: 0.0100\n",
      "Episode: 299 Total reward: 200.0000 Training loss: 165.2286 Epsilon: 0.0100\n",
      "Episode: 300 Total reward: 196.0000 Training loss: 234.1610 Epsilon: 0.0100\n",
      "Episode: 301 Total reward: 200.0000 Training loss: 97.9468 Epsilon: 0.0100\n",
      "Episode: 302 Total reward: 200.0000 Training loss: 101.3098 Epsilon: 0.0100\n",
      "Episode: 303 Total reward: 200.0000 Training loss: 161.7843 Epsilon: 0.0100\n",
      "Episode: 304 Total reward: 200.0000 Training loss: 108.4453 Epsilon: 0.0100\n",
      "Episode: 305 Total reward: 200.0000 Training loss: 225.1621 Epsilon: 0.0100\n",
      "Episode: 306 Total reward: 200.0000 Training loss: 73.2119 Epsilon: 0.0100\n",
      "Episode: 307 Total reward: 200.0000 Training loss: 156.9359 Epsilon: 0.0100\n",
      "Episode: 308 Total reward: 200.0000 Training loss: 137.6375 Epsilon: 0.0100\n",
      "Episode: 309 Total reward: 200.0000 Training loss: 359.3397 Epsilon: 0.0100\n",
      "Episode: 310 Total reward: 200.0000 Training loss: 1354.1891 Epsilon: 0.0100\n",
      "Episode: 311 Total reward: 200.0000 Training loss: 181.1077 Epsilon: 0.0100\n",
      "Episode: 312 Total reward: 200.0000 Training loss: 14118.2256 Epsilon: 0.0100\n",
      "Episode: 313 Total reward: 200.0000 Training loss: 74.9955 Epsilon: 0.0100\n",
      "Episode: 314 Total reward: 200.0000 Training loss: 922.1699 Epsilon: 0.0100\n",
      "Episode: 315 Total reward: 200.0000 Training loss: 76.5751 Epsilon: 0.0100\n",
      "Episode: 316 Total reward: 200.0000 Training loss: 602.5113 Epsilon: 0.0100\n",
      "Episode: 317 Total reward: 200.0000 Training loss: 11845.9004 Epsilon: 0.0100\n",
      "Episode: 318 Total reward: 200.0000 Training loss: 133.5498 Epsilon: 0.0100\n",
      "Episode: 319 Total reward: 200.0000 Training loss: 164.4798 Epsilon: 0.0100\n",
      "Episode: 320 Total reward: 200.0000 Training loss: 81.1497 Epsilon: 0.0100\n",
      "Episode: 321 Total reward: 200.0000 Training loss: 1461.6652 Epsilon: 0.0100\n",
      "Episode: 322 Total reward: 200.0000 Training loss: 1986.1040 Epsilon: 0.0100\n",
      "Episode: 323 Total reward: 200.0000 Training loss: 58.9573 Epsilon: 0.0100\n",
      "Episode: 324 Total reward: 200.0000 Training loss: 92.5578 Epsilon: 0.0100\n",
      "Episode: 325 Total reward: 200.0000 Training loss: 27.2459 Epsilon: 0.0100\n",
      "Episode: 326 Total reward: 200.0000 Training loss: 1180.9098 Epsilon: 0.0100\n",
      "Episode: 327 Total reward: 200.0000 Training loss: 179.3222 Epsilon: 0.0100\n",
      "Episode: 328 Total reward: 200.0000 Training loss: 101.2024 Epsilon: 0.0100\n",
      "Episode: 329 Total reward: 200.0000 Training loss: 60.0042 Epsilon: 0.0100\n",
      "Episode: 330 Total reward: 200.0000 Training loss: 93.9602 Epsilon: 0.0100\n",
      "Episode: 331 Total reward: 200.0000 Training loss: 135.8783 Epsilon: 0.0100\n",
      "Episode: 332 Total reward: 200.0000 Training loss: 203.2928 Epsilon: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 333 Total reward: 200.0000 Training loss: 523.0735 Epsilon: 0.0100\n",
      "Episode: 334 Total reward: 200.0000 Training loss: 2091.5845 Epsilon: 0.0100\n",
      "Episode: 335 Total reward: 200.0000 Training loss: 288014.9062 Epsilon: 0.0100\n",
      "Episode: 336 Total reward: 200.0000 Training loss: 6445.9160 Epsilon: 0.0100\n",
      "Episode: 337 Total reward: 200.0000 Training loss: 5540.6689 Epsilon: 0.0100\n",
      "Episode: 338 Total reward: 200.0000 Training loss: 10165.0938 Epsilon: 0.0100\n",
      "Episode: 339 Total reward: 200.0000 Training loss: 11856.6699 Epsilon: 0.0100\n",
      "Episode: 340 Total reward: 200.0000 Training loss: 10565.4551 Epsilon: 0.0100\n",
      "Episode: 341 Total reward: 200.0000 Training loss: 10987.9131 Epsilon: 0.0100\n",
      "Episode: 342 Total reward: 200.0000 Training loss: 12132.3545 Epsilon: 0.0100\n",
      "Episode: 343 Total reward: 200.0000 Training loss: 39613.8242 Epsilon: 0.0100\n",
      "Episode: 344 Total reward: 200.0000 Training loss: 10960.1494 Epsilon: 0.0100\n",
      "Episode: 345 Total reward: 200.0000 Training loss: 14840.3320 Epsilon: 0.0100\n",
      "Episode: 346 Total reward: 200.0000 Training loss: 7062.9233 Epsilon: 0.0100\n",
      "Episode: 347 Total reward: 200.0000 Training loss: 26816.8594 Epsilon: 0.0100\n",
      "Episode: 348 Total reward: 200.0000 Training loss: 18035.7832 Epsilon: 0.0100\n",
      "Episode: 349 Total reward: 200.0000 Training loss: 20384.0273 Epsilon: 0.0100\n",
      "Episode: 350 Total reward: 200.0000 Training loss: 36560.9766 Epsilon: 0.0100\n",
      "Episode: 351 Total reward: 200.0000 Training loss: 43578.0703 Epsilon: 0.0100\n",
      "Episode: 352 Total reward: 200.0000 Training loss: 1129358.7500 Epsilon: 0.0100\n",
      "Episode: 353 Total reward: 200.0000 Training loss: 19395.8125 Epsilon: 0.0100\n",
      "Episode: 354 Total reward: 200.0000 Training loss: 8597.0498 Epsilon: 0.0100\n",
      "Episode: 355 Total reward: 200.0000 Training loss: 3220048.0000 Epsilon: 0.0100\n",
      "Episode: 356 Total reward: 200.0000 Training loss: 30835.1191 Epsilon: 0.0100\n",
      "Episode: 357 Total reward: 200.0000 Training loss: 307148.1875 Epsilon: 0.0100\n",
      "Episode: 358 Total reward: 200.0000 Training loss: 36685.5664 Epsilon: 0.0100\n",
      "Episode: 359 Total reward: 200.0000 Training loss: 3314738.2500 Epsilon: 0.0100\n",
      "Episode: 360 Total reward: 200.0000 Training loss: 34707.8477 Epsilon: 0.0100\n",
      "Episode: 361 Total reward: 200.0000 Training loss: 22252.6367 Epsilon: 0.0100\n",
      "Episode: 362 Total reward: 200.0000 Training loss: 18444.1797 Epsilon: 0.0100\n",
      "Episode: 363 Total reward: 200.0000 Training loss: 29701.1816 Epsilon: 0.0100\n",
      "Episode: 364 Total reward: 200.0000 Training loss: 47436.7266 Epsilon: 0.0100\n",
      "Episode: 365 Total reward: 200.0000 Training loss: 55574.9609 Epsilon: 0.0100\n",
      "Episode: 366 Total reward: 200.0000 Training loss: 11861.1445 Epsilon: 0.0100\n",
      "Episode: 367 Total reward: 200.0000 Training loss: 35959.2383 Epsilon: 0.0100\n",
      "Episode: 368 Total reward: 200.0000 Training loss: 20479.5293 Epsilon: 0.0100\n",
      "Episode: 369 Total reward: 200.0000 Training loss: 43952.5586 Epsilon: 0.0100\n",
      "Episode: 370 Total reward: 200.0000 Training loss: 31166.5391 Epsilon: 0.0100\n",
      "Episode: 371 Total reward: 200.0000 Training loss: 22980.9922 Epsilon: 0.0100\n",
      "Episode: 372 Total reward: 200.0000 Training loss: 23461.1465 Epsilon: 0.0100\n",
      "Episode: 373 Total reward: 200.0000 Training loss: 9906.9346 Epsilon: 0.0100\n",
      "Episode: 374 Total reward: 200.0000 Training loss: 33982.9570 Epsilon: 0.0100\n",
      "Episode: 375 Total reward: 200.0000 Training loss: 18452.9668 Epsilon: 0.0100\n",
      "Episode: 376 Total reward: 200.0000 Training loss: 1530610.1250 Epsilon: 0.0100\n",
      "Episode: 377 Total reward: 200.0000 Training loss: 10560.9443 Epsilon: 0.0100\n",
      "Episode: 378 Total reward: 200.0000 Training loss: 8689.2871 Epsilon: 0.0100\n",
      "Episode: 379 Total reward: 200.0000 Training loss: 14522.5635 Epsilon: 0.0100\n",
      "Episode: 380 Total reward: 200.0000 Training loss: 9313.5771 Epsilon: 0.0100\n",
      "Episode: 381 Total reward: 200.0000 Training loss: 54320.6953 Epsilon: 0.0100\n",
      "Episode: 382 Total reward: 200.0000 Training loss: 48079.5117 Epsilon: 0.0100\n",
      "Episode: 383 Total reward: 200.0000 Training loss: 39293.6797 Epsilon: 0.0100\n",
      "Episode: 384 Total reward: 200.0000 Training loss: 11866.7812 Epsilon: 0.0100\n",
      "Episode: 385 Total reward: 200.0000 Training loss: 38691.4453 Epsilon: 0.0100\n",
      "Episode: 386 Total reward: 200.0000 Training loss: 20047.0039 Epsilon: 0.0100\n",
      "Episode: 387 Total reward: 200.0000 Training loss: 12156.6494 Epsilon: 0.0100\n",
      "Episode: 388 Total reward: 196.0000 Training loss: 15502.0537 Epsilon: 0.0100\n",
      "Episode: 389 Total reward: 200.0000 Training loss: 7660.1558 Epsilon: 0.0100\n",
      "Episode: 390 Total reward: 200.0000 Training loss: 12095.0742 Epsilon: 0.0100\n",
      "Episode: 391 Total reward: 200.0000 Training loss: 40338.5938 Epsilon: 0.0100\n",
      "Episode: 392 Total reward: 200.0000 Training loss: 2338381.5000 Epsilon: 0.0100\n",
      "Episode: 393 Total reward: 200.0000 Training loss: 10185.7559 Epsilon: 0.0100\n",
      "Episode: 394 Total reward: 200.0000 Training loss: 25350.3789 Epsilon: 0.0100\n",
      "Gym solved!\n",
      "Final Episode: 394\n"
     ]
    }
   ],
   "source": [
    "def train_agent():\n",
    "    # Intantiate memory and populate\n",
    "    exp_replay = Memory_exp_replay(memory_size)\n",
    "    exp_replay = populate_memory(env, exp_replay, batch_size_Q)\n",
    "\n",
    "    # Initiliaze TensorFlow Graph\n",
    "    tf.reset_default_graph()\n",
    "    Q_NN_target = NN_Q_approx(learning_rate=learning_rate_nn, hidden_size=hidden_size, state_space=state_space, action_space=action_space, name='Q_action_target')\n",
    "    Q_NN_grad = NN_Q_approx(learning_rate=learning_rate_nn, hidden_size=hidden_size, state_space=state_space, action_space=action_space, name='Q_action_grad')\n",
    "    assigns = relate_variables_NN(Q_NN_target, Q_NN_grad)\n",
    "\n",
    "    training_rewards = list()\n",
    "    training_loss = list()\n",
    "    with tf.Session() as sess:\n",
    "        # Initializa variables \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ep_iter = 0\n",
    "\n",
    "        for i in range(1, max_episodes+1):\n",
    "            # Intiliazing variables for episode.\n",
    "            s_t1 = env.reset()\n",
    "            time_step = 0\n",
    "            episode_reward = 0\n",
    "\n",
    "            while time_step < max_steps_episode:\n",
    "                # Watch it learn.\n",
    "                # env.render()\n",
    "\n",
    "                s_t = s_t1\n",
    "                # Controling epsilon.\n",
    "                ep_iter += 1\n",
    "                epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*i) \n",
    "\n",
    "                # Find Q Values and select action under E-greedy policy.\n",
    "                q_values = sess.run(Q_NN_grad.output, feed_dict={Q_NN_grad.inputs:np.array(s_t).reshape((1, -1))})\n",
    "                a_t = epsilon_greedy(epsilon, q_values)\n",
    "\n",
    "                s_t1, r_t1, done, info = env.step(a_t)\n",
    "\n",
    "                episode_reward += gamma*r_t1\n",
    "                time_step += 1\n",
    "\n",
    "                if done:\n",
    "                    # Terminating episode\n",
    "                    time_step = max_steps_episode\n",
    "                    s_t1 = np.zeros(state_space)\n",
    "                    # Update memory\n",
    "                    exp_replay.add_timestep((s_t, a_t, r_t1, s_t1))\n",
    "\n",
    "                    # Tracking information\n",
    "                    training_rewards.append((i, episode_reward))\n",
    "                    training_loss.append((i, loss))\n",
    "                    print('Episode: {}'.format(i),\n",
    "\n",
    "\n",
    "                          'Total reward: {:.4f}'.format(episode_reward),\n",
    "                          'Training loss: {:.4f}'.format(loss),\n",
    "                          'Epsilon: {:.4f}'.format(epsilon))\n",
    "                else:\n",
    "                    # Update memory\n",
    "                    exp_replay.add_timestep((s_t, a_t, r_t1, s_t1))\n",
    "\n",
    "                # Train network.\n",
    "                states, actions, rewards, next_states = exp_replay.sample_random(batch_size_Q)\n",
    "\n",
    "                estimated_Qs = sess.run(Q_NN_target.output, feed_dict = {Q_NN_target.inputs:next_states})\n",
    "                action_Qs = sess.run(Q_NN_grad.output, feed_dict = {Q_NN_grad.inputs:next_states})\n",
    "                found_initial = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "                estimated_Qs[found_initial] = np.zeros(estimated_Qs[0].shape)\n",
    "                action_Qs[found_initial] = np.zeros(estimated_Qs[0].shape)\n",
    "\n",
    "                actions_t = (action_Qs==np.amax(action_Qs, axis=1, keepdims=True))\n",
    "                target_Qs = rewards + gamma*np.max(estimated_Qs*actions_t, axis=1)\n",
    "\n",
    "                feed_dict = {Q_NN_grad.inputs:states, Q_NN_grad.actions:actions, Q_NN_grad.target_Q: target_Qs}\n",
    "                loss, _ = sess.run([Q_NN_grad.loss, Q_NN_grad.opt], feed_dict)\n",
    "\n",
    "                if ep_iter%update_nn_target==0:\n",
    "                    update_values_sess(sess, assigns)\n",
    "\n",
    "                if (len(training_rewards)>=100) and (np.array(training_rewards[-100:])>= 195).all():\n",
    "                    print('Gym solved!')\n",
    "                    print('Final Episode:', i)\n",
    "                    return training_loss, training_rewards\n",
    "    return training_loss, training_rewards\n",
    "\n",
    "training_loss, training_rewards = train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niqL4ogKhKIqi+PL/A9qJYqWXhuJhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x314512438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N \n",
    "\n",
    "eps, rews = np.array(training_rewards).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='blue', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEKCAYAAAC7c+rvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwrgImZlZYVyEzMysMP8fOhHPRbfUoIQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x31452b7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, loss = np.array(training_loss).T\n",
    "plt.plot(loss, color='blue')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 17.0000 Training loss: 1.0459 Epsilon: 0.9517\n",
      "Episode: 2 Total reward: 32.0000 Training loss: 0.9712 Epsilon: 0.9058\n",
      "Episode: 3 Total reward: 13.0000 Training loss: 0.9131 Epsilon: 0.8621\n",
      "Episode: 4 Total reward: 18.0000 Training loss: 0.9931 Epsilon: 0.8205\n",
      "Episode: 5 Total reward: 14.0000 Training loss: 1.0721 Epsilon: 0.7810\n",
      "Episode: 6 Total reward: 13.0000 Training loss: 1.0049 Epsilon: 0.7434\n",
      "Episode: 7 Total reward: 18.0000 Training loss: 0.9945 Epsilon: 0.7076\n",
      "Episode: 8 Total reward: 10.0000 Training loss: 0.9498 Epsilon: 0.6736\n",
      "Episode: 9 Total reward: 10.0000 Training loss: 1.1793 Epsilon: 0.6413\n",
      "Episode: 10 Total reward: 12.0000 Training loss: 1.0382 Epsilon: 0.6105\n",
      "Episode: 11 Total reward: 13.0000 Training loss: 1.1441 Epsilon: 0.5812\n",
      "Episode: 12 Total reward: 12.0000 Training loss: 1.1305 Epsilon: 0.5533\n",
      "Episode: 13 Total reward: 15.0000 Training loss: 1.0584 Epsilon: 0.5268\n",
      "Episode: 14 Total reward: 18.0000 Training loss: 1.3204 Epsilon: 0.5016\n",
      "Episode: 15 Total reward: 14.0000 Training loss: 1.6233 Epsilon: 0.4776\n",
      "Episode: 16 Total reward: 35.0000 Training loss: 1.4792 Epsilon: 0.4548\n",
      "Episode: 17 Total reward: 10.0000 Training loss: 1.5340 Epsilon: 0.4331\n",
      "Episode: 18 Total reward: 11.0000 Training loss: 1.4688 Epsilon: 0.4125\n",
      "Episode: 19 Total reward: 14.0000 Training loss: 1.6746 Epsilon: 0.3929\n",
      "Episode: 20 Total reward: 13.0000 Training loss: 1.9627 Epsilon: 0.3742\n",
      "Episode: 21 Total reward: 13.0000 Training loss: 1.6716 Epsilon: 0.3564\n",
      "Episode: 22 Total reward: 14.0000 Training loss: 1.9712 Epsilon: 0.3395\n",
      "Episode: 23 Total reward: 8.0000 Training loss: 1.6985 Epsilon: 0.3235\n",
      "Episode: 24 Total reward: 11.0000 Training loss: 1.8780 Epsilon: 0.3082\n",
      "Episode: 25 Total reward: 9.0000 Training loss: 1.8586 Epsilon: 0.2936\n",
      "Episode: 26 Total reward: 11.0000 Training loss: 2.0306 Epsilon: 0.2798\n",
      "Episode: 27 Total reward: 9.0000 Training loss: 2.3725 Epsilon: 0.2666\n",
      "Episode: 28 Total reward: 9.0000 Training loss: 2.8595 Epsilon: 0.2541\n",
      "Episode: 29 Total reward: 17.0000 Training loss: 3.1808 Epsilon: 0.2422\n",
      "Episode: 30 Total reward: 11.0000 Training loss: 2.2551 Epsilon: 0.2309\n",
      "Episode: 31 Total reward: 10.0000 Training loss: 1.9707 Epsilon: 0.2201\n",
      "Episode: 32 Total reward: 11.0000 Training loss: 3.7329 Epsilon: 0.2099\n",
      "Episode: 33 Total reward: 11.0000 Training loss: 3.2047 Epsilon: 0.2001\n",
      "Episode: 34 Total reward: 9.0000 Training loss: 4.3785 Epsilon: 0.1909\n",
      "Episode: 35 Total reward: 10.0000 Training loss: 3.0279 Epsilon: 0.1820\n",
      "Episode: 36 Total reward: 9.0000 Training loss: 3.3047 Epsilon: 0.1736\n",
      "Episode: 37 Total reward: 14.0000 Training loss: 3.3978 Epsilon: 0.1657\n",
      "Episode: 38 Total reward: 11.0000 Training loss: 2.4949 Epsilon: 0.1581\n",
      "Episode: 39 Total reward: 8.0000 Training loss: 2.0584 Epsilon: 0.1509\n",
      "Episode: 40 Total reward: 9.0000 Training loss: 1.8375 Epsilon: 0.1440\n",
      "Episode: 41 Total reward: 10.0000 Training loss: 4.3272 Epsilon: 0.1374\n",
      "Episode: 42 Total reward: 8.0000 Training loss: 3.0768 Epsilon: 0.1312\n",
      "Episode: 43 Total reward: 10.0000 Training loss: 3.0410 Epsilon: 0.1253\n",
      "Episode: 44 Total reward: 10.0000 Training loss: 6.1866 Epsilon: 0.1197\n",
      "Episode: 45 Total reward: 9.0000 Training loss: 3.6612 Epsilon: 0.1143\n",
      "Episode: 46 Total reward: 10.0000 Training loss: 7.5097 Epsilon: 0.1093\n",
      "Episode: 47 Total reward: 10.0000 Training loss: 5.7325 Epsilon: 0.1044\n",
      "Episode: 48 Total reward: 10.0000 Training loss: 6.3683 Epsilon: 0.0998\n",
      "Episode: 49 Total reward: 9.0000 Training loss: 3.3815 Epsilon: 0.0954\n",
      "Episode: 50 Total reward: 10.0000 Training loss: 5.6879 Epsilon: 0.0913\n",
      "Episode: 51 Total reward: 11.0000 Training loss: 7.2711 Epsilon: 0.0873\n",
      "Episode: 52 Total reward: 10.0000 Training loss: 4.5260 Epsilon: 0.0835\n",
      "Episode: 53 Total reward: 9.0000 Training loss: 9.3808 Epsilon: 0.0799\n",
      "Episode: 54 Total reward: 9.0000 Training loss: 2.5108 Epsilon: 0.0765\n",
      "Episode: 55 Total reward: 10.0000 Training loss: 6.1107 Epsilon: 0.0733\n",
      "Episode: 56 Total reward: 10.0000 Training loss: 5.6934 Epsilon: 0.0702\n",
      "Episode: 57 Total reward: 9.0000 Training loss: 11.4378 Epsilon: 0.0673\n",
      "Episode: 58 Total reward: 9.0000 Training loss: 4.8574 Epsilon: 0.0645\n",
      "Episode: 59 Total reward: 12.0000 Training loss: 8.4700 Epsilon: 0.0618\n",
      "Episode: 60 Total reward: 9.0000 Training loss: 12.0224 Epsilon: 0.0593\n",
      "Episode: 61 Total reward: 8.0000 Training loss: 8.9315 Epsilon: 0.0569\n",
      "Episode: 62 Total reward: 9.0000 Training loss: 6.4559 Epsilon: 0.0546\n",
      "Episode: 63 Total reward: 10.0000 Training loss: 5.0731 Epsilon: 0.0524\n",
      "Episode: 64 Total reward: 9.0000 Training loss: 7.1339 Epsilon: 0.0504\n",
      "Episode: 65 Total reward: 9.0000 Training loss: 6.5381 Epsilon: 0.0484\n",
      "Episode: 66 Total reward: 10.0000 Training loss: 15.5142 Epsilon: 0.0465\n",
      "Episode: 67 Total reward: 10.0000 Training loss: 14.2201 Epsilon: 0.0447\n",
      "Episode: 68 Total reward: 10.0000 Training loss: 15.0547 Epsilon: 0.0430\n",
      "Episode: 69 Total reward: 9.0000 Training loss: 13.5056 Epsilon: 0.0414\n",
      "Episode: 70 Total reward: 10.0000 Training loss: 5.5461 Epsilon: 0.0399\n",
      "Episode: 71 Total reward: 11.0000 Training loss: 15.5831 Epsilon: 0.0384\n",
      "Episode: 72 Total reward: 10.0000 Training loss: 10.7816 Epsilon: 0.0371\n",
      "Episode: 73 Total reward: 10.0000 Training loss: 4.0173 Epsilon: 0.0357\n",
      "Episode: 74 Total reward: 8.0000 Training loss: 9.4484 Epsilon: 0.0345\n",
      "Episode: 75 Total reward: 8.0000 Training loss: 13.7931 Epsilon: 0.0333\n",
      "Episode: 76 Total reward: 10.0000 Training loss: 15.4815 Epsilon: 0.0321\n",
      "Episode: 77 Total reward: 10.0000 Training loss: 9.1737 Epsilon: 0.0311\n",
      "Episode: 78 Total reward: 10.0000 Training loss: 4.4449 Epsilon: 0.0300\n",
      "Episode: 79 Total reward: 10.0000 Training loss: 17.4962 Epsilon: 0.0291\n",
      "Episode: 80 Total reward: 9.0000 Training loss: 14.4377 Epsilon: 0.0281\n",
      "Episode: 81 Total reward: 11.0000 Training loss: 16.0149 Epsilon: 0.0272\n",
      "Episode: 82 Total reward: 8.0000 Training loss: 16.2552 Epsilon: 0.0264\n",
      "Episode: 83 Total reward: 9.0000 Training loss: 12.2794 Epsilon: 0.0256\n",
      "Episode: 84 Total reward: 9.0000 Training loss: 16.5534 Epsilon: 0.0248\n",
      "Episode: 85 Total reward: 10.0000 Training loss: 13.7840 Epsilon: 0.0241\n",
      "Episode: 86 Total reward: 8.0000 Training loss: 10.5436 Epsilon: 0.0234\n",
      "Episode: 87 Total reward: 11.0000 Training loss: 18.0525 Epsilon: 0.0228\n",
      "Episode: 88 Total reward: 10.0000 Training loss: 14.3010 Epsilon: 0.0222\n",
      "Episode: 89 Total reward: 11.0000 Training loss: 16.4653 Epsilon: 0.0216\n",
      "Episode: 90 Total reward: 9.0000 Training loss: 7.2517 Epsilon: 0.0210\n",
      "Episode: 91 Total reward: 9.0000 Training loss: 3.8979 Epsilon: 0.0205\n",
      "Episode: 92 Total reward: 10.0000 Training loss: 11.9687 Epsilon: 0.0200\n",
      "Episode: 93 Total reward: 9.0000 Training loss: 14.0964 Epsilon: 0.0195\n",
      "Episode: 94 Total reward: 10.0000 Training loss: 7.7280 Epsilon: 0.0190\n",
      "Episode: 95 Total reward: 11.0000 Training loss: 11.9481 Epsilon: 0.0186\n",
      "Episode: 96 Total reward: 10.0000 Training loss: 12.3741 Epsilon: 0.0181\n",
      "Episode: 97 Total reward: 9.0000 Training loss: 15.5921 Epsilon: 0.0178\n",
      "Episode: 98 Total reward: 8.0000 Training loss: 12.7610 Epsilon: 0.0174\n",
      "Episode: 99 Total reward: 10.0000 Training loss: 18.1767 Epsilon: 0.0170\n",
      "Episode: 100 Total reward: 9.0000 Training loss: 3.5421 Epsilon: 0.0167\n",
      "Episode: 101 Total reward: 9.0000 Training loss: 16.8721 Epsilon: 0.0163\n",
      "Episode: 102 Total reward: 11.0000 Training loss: 6.2918 Epsilon: 0.0160\n",
      "Episode: 103 Total reward: 11.0000 Training loss: 9.9085 Epsilon: 0.0157\n",
      "Episode: 104 Total reward: 10.0000 Training loss: 13.9990 Epsilon: 0.0155\n",
      "Episode: 105 Total reward: 8.0000 Training loss: 12.7873 Epsilon: 0.0152\n",
      "Episode: 106 Total reward: 9.0000 Training loss: 18.4623 Epsilon: 0.0149\n",
      "Episode: 107 Total reward: 9.0000 Training loss: 12.8689 Epsilon: 0.0147\n",
      "Episode: 108 Total reward: 9.0000 Training loss: 4.6943 Epsilon: 0.0145\n",
      "Episode: 109 Total reward: 11.0000 Training loss: 14.7705 Epsilon: 0.0143\n",
      "Episode: 110 Total reward: 8.0000 Training loss: 10.9207 Epsilon: 0.0140\n",
      "Episode: 111 Total reward: 10.0000 Training loss: 19.6826 Epsilon: 0.0138\n",
      "Episode: 112 Total reward: 11.0000 Training loss: 15.4993 Epsilon: 0.0137\n",
      "Episode: 113 Total reward: 9.0000 Training loss: 14.2507 Epsilon: 0.0135\n",
      "Episode: 114 Total reward: 10.0000 Training loss: 13.3105 Epsilon: 0.0133\n",
      "Episode: 115 Total reward: 10.0000 Training loss: 12.6580 Epsilon: 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 116 Total reward: 10.0000 Training loss: 15.2201 Epsilon: 0.0130\n",
      "Episode: 117 Total reward: 9.0000 Training loss: 11.6694 Epsilon: 0.0129\n",
      "Episode: 118 Total reward: 10.0000 Training loss: 16.5708 Epsilon: 0.0127\n",
      "Episode: 119 Total reward: 10.0000 Training loss: 12.2584 Epsilon: 0.0126\n",
      "Episode: 120 Total reward: 10.0000 Training loss: 12.4759 Epsilon: 0.0125\n",
      "Episode: 121 Total reward: 9.0000 Training loss: 7.4600 Epsilon: 0.0123\n",
      "Episode: 122 Total reward: 9.0000 Training loss: 13.5102 Epsilon: 0.0122\n",
      "Episode: 123 Total reward: 9.0000 Training loss: 5.1451 Epsilon: 0.0121\n",
      "Episode: 124 Total reward: 10.0000 Training loss: 4.3305 Epsilon: 0.0120\n",
      "Episode: 125 Total reward: 8.0000 Training loss: 9.6642 Epsilon: 0.0119\n",
      "Episode: 126 Total reward: 9.0000 Training loss: 10.8794 Epsilon: 0.0118\n",
      "Episode: 127 Total reward: 10.0000 Training loss: 11.1629 Epsilon: 0.0117\n",
      "Episode: 128 Total reward: 9.0000 Training loss: 14.9887 Epsilon: 0.0116\n",
      "Episode: 129 Total reward: 9.0000 Training loss: 19.0098 Epsilon: 0.0116\n",
      "Episode: 130 Total reward: 8.0000 Training loss: 9.9193 Epsilon: 0.0115\n",
      "Episode: 131 Total reward: 8.0000 Training loss: 5.2339 Epsilon: 0.0114\n",
      "Episode: 132 Total reward: 10.0000 Training loss: 6.4031 Epsilon: 0.0113\n",
      "Episode: 133 Total reward: 8.0000 Training loss: 9.6748 Epsilon: 0.0113\n",
      "Episode: 134 Total reward: 10.0000 Training loss: 9.4357 Epsilon: 0.0112\n",
      "Episode: 135 Total reward: 8.0000 Training loss: 9.3773 Epsilon: 0.0112\n",
      "Episode: 136 Total reward: 9.0000 Training loss: 10.0976 Epsilon: 0.0111\n",
      "Episode: 137 Total reward: 9.0000 Training loss: 4.3586 Epsilon: 0.0110\n",
      "Episode: 138 Total reward: 8.0000 Training loss: 7.2987 Epsilon: 0.0110\n",
      "Episode: 139 Total reward: 9.0000 Training loss: 6.6412 Epsilon: 0.0109\n",
      "Episode: 140 Total reward: 10.0000 Training loss: 9.3749 Epsilon: 0.0109\n",
      "Episode: 141 Total reward: 9.0000 Training loss: 9.3286 Epsilon: 0.0109\n",
      "Episode: 142 Total reward: 10.0000 Training loss: 1.9510 Epsilon: 0.0108\n",
      "Episode: 143 Total reward: 10.0000 Training loss: 5.5537 Epsilon: 0.0108\n",
      "Episode: 144 Total reward: 8.0000 Training loss: 10.3838 Epsilon: 0.0107\n",
      "Episode: 145 Total reward: 8.0000 Training loss: 11.0650 Epsilon: 0.0107\n",
      "Episode: 146 Total reward: 10.0000 Training loss: 5.5769 Epsilon: 0.0107\n",
      "Episode: 147 Total reward: 11.0000 Training loss: 8.5142 Epsilon: 0.0106\n",
      "Episode: 148 Total reward: 10.0000 Training loss: 5.2862 Epsilon: 0.0106\n",
      "Episode: 149 Total reward: 9.0000 Training loss: 7.0648 Epsilon: 0.0106\n",
      "Episode: 150 Total reward: 9.0000 Training loss: 9.1296 Epsilon: 0.0105\n",
      "Episode: 151 Total reward: 9.0000 Training loss: 9.5880 Epsilon: 0.0105\n",
      "Episode: 152 Total reward: 10.0000 Training loss: 6.6080 Epsilon: 0.0105\n",
      "Episode: 153 Total reward: 9.0000 Training loss: 13.7380 Epsilon: 0.0105\n",
      "Episode: 154 Total reward: 9.0000 Training loss: 6.3495 Epsilon: 0.0104\n",
      "Episode: 155 Total reward: 11.0000 Training loss: 3.1285 Epsilon: 0.0104\n",
      "Episode: 156 Total reward: 11.0000 Training loss: 4.6590 Epsilon: 0.0104\n",
      "Episode: 157 Total reward: 10.0000 Training loss: 5.5435 Epsilon: 0.0104\n",
      "Episode: 158 Total reward: 11.0000 Training loss: 5.5965 Epsilon: 0.0104\n",
      "Episode: 159 Total reward: 9.0000 Training loss: 6.9285 Epsilon: 0.0103\n",
      "Episode: 160 Total reward: 11.0000 Training loss: 7.6241 Epsilon: 0.0103\n",
      "Episode: 161 Total reward: 9.0000 Training loss: 2.7776 Epsilon: 0.0103\n",
      "Episode: 162 Total reward: 10.0000 Training loss: 10.0273 Epsilon: 0.0103\n",
      "Episode: 163 Total reward: 11.0000 Training loss: 5.7331 Epsilon: 0.0103\n",
      "Episode: 164 Total reward: 9.0000 Training loss: 9.4552 Epsilon: 0.0103\n",
      "Episode: 165 Total reward: 9.0000 Training loss: 6.2678 Epsilon: 0.0103\n",
      "Episode: 166 Total reward: 11.0000 Training loss: 3.7715 Epsilon: 0.0102\n",
      "Episode: 167 Total reward: 9.0000 Training loss: 5.7264 Epsilon: 0.0102\n",
      "Episode: 168 Total reward: 10.0000 Training loss: 4.1213 Epsilon: 0.0102\n",
      "Episode: 169 Total reward: 10.0000 Training loss: 2.7901 Epsilon: 0.0102\n",
      "Episode: 170 Total reward: 9.0000 Training loss: 4.0288 Epsilon: 0.0102\n",
      "Episode: 171 Total reward: 9.0000 Training loss: 3.2511 Epsilon: 0.0102\n",
      "Episode: 172 Total reward: 9.0000 Training loss: 8.9655 Epsilon: 0.0102\n",
      "Episode: 173 Total reward: 10.0000 Training loss: 6.9970 Epsilon: 0.0102\n",
      "Episode: 174 Total reward: 9.0000 Training loss: 6.4461 Epsilon: 0.0102\n",
      "Episode: 175 Total reward: 11.0000 Training loss: 8.2842 Epsilon: 0.0102\n",
      "Episode: 176 Total reward: 9.0000 Training loss: 5.1905 Epsilon: 0.0101\n",
      "Episode: 177 Total reward: 10.0000 Training loss: 7.1151 Epsilon: 0.0101\n",
      "Episode: 178 Total reward: 11.0000 Training loss: 2.5762 Epsilon: 0.0101\n",
      "Episode: 179 Total reward: 11.0000 Training loss: 3.2885 Epsilon: 0.0101\n",
      "Episode: 180 Total reward: 11.0000 Training loss: 5.5342 Epsilon: 0.0101\n",
      "Episode: 181 Total reward: 9.0000 Training loss: 4.5128 Epsilon: 0.0101\n",
      "Episode: 182 Total reward: 11.0000 Training loss: 4.4694 Epsilon: 0.0101\n",
      "Episode: 183 Total reward: 11.0000 Training loss: 3.8076 Epsilon: 0.0101\n",
      "Episode: 184 Total reward: 9.0000 Training loss: 4.0819 Epsilon: 0.0101\n",
      "Episode: 185 Total reward: 9.0000 Training loss: 4.2095 Epsilon: 0.0101\n",
      "Episode: 186 Total reward: 10.0000 Training loss: 6.3655 Epsilon: 0.0101\n",
      "Episode: 187 Total reward: 9.0000 Training loss: 3.5076 Epsilon: 0.0101\n",
      "Episode: 188 Total reward: 10.0000 Training loss: 4.5062 Epsilon: 0.0101\n",
      "Episode: 189 Total reward: 9.0000 Training loss: 4.0784 Epsilon: 0.0101\n",
      "Episode: 190 Total reward: 11.0000 Training loss: 2.8662 Epsilon: 0.0101\n",
      "Episode: 191 Total reward: 11.0000 Training loss: 4.8551 Epsilon: 0.0101\n",
      "Episode: 192 Total reward: 9.0000 Training loss: 3.5320 Epsilon: 0.0101\n",
      "Episode: 193 Total reward: 9.0000 Training loss: 1.8474 Epsilon: 0.0101\n",
      "Episode: 194 Total reward: 10.0000 Training loss: 4.9962 Epsilon: 0.0101\n",
      "Episode: 195 Total reward: 9.0000 Training loss: 0.5049 Epsilon: 0.0101\n",
      "Episode: 196 Total reward: 10.0000 Training loss: 4.8370 Epsilon: 0.0101\n",
      "Episode: 197 Total reward: 10.0000 Training loss: 3.1711 Epsilon: 0.0101\n",
      "Episode: 198 Total reward: 11.0000 Training loss: 3.5869 Epsilon: 0.0100\n",
      "Episode: 199 Total reward: 9.0000 Training loss: 1.2151 Epsilon: 0.0100\n",
      "Episode: 200 Total reward: 11.0000 Training loss: 5.3460 Epsilon: 0.0100\n",
      "Episode: 201 Total reward: 10.0000 Training loss: 3.2857 Epsilon: 0.0100\n",
      "Episode: 202 Total reward: 10.0000 Training loss: 4.0277 Epsilon: 0.0100\n",
      "Episode: 203 Total reward: 11.0000 Training loss: 1.2921 Epsilon: 0.0100\n",
      "Episode: 204 Total reward: 8.0000 Training loss: 2.1626 Epsilon: 0.0100\n",
      "Episode: 205 Total reward: 9.0000 Training loss: 4.6796 Epsilon: 0.0100\n",
      "Episode: 206 Total reward: 11.0000 Training loss: 4.9923 Epsilon: 0.0100\n",
      "Episode: 207 Total reward: 8.0000 Training loss: 3.4270 Epsilon: 0.0100\n",
      "Episode: 208 Total reward: 10.0000 Training loss: 4.7630 Epsilon: 0.0100\n",
      "Episode: 209 Total reward: 9.0000 Training loss: 4.0656 Epsilon: 0.0100\n",
      "Episode: 210 Total reward: 12.0000 Training loss: 4.3191 Epsilon: 0.0100\n",
      "Episode: 211 Total reward: 9.0000 Training loss: 0.9622 Epsilon: 0.0100\n",
      "Episode: 212 Total reward: 10.0000 Training loss: 2.6163 Epsilon: 0.0100\n",
      "Episode: 213 Total reward: 11.0000 Training loss: 3.4081 Epsilon: 0.0100\n",
      "Episode: 214 Total reward: 10.0000 Training loss: 3.6464 Epsilon: 0.0100\n",
      "Episode: 215 Total reward: 10.0000 Training loss: 4.0519 Epsilon: 0.0100\n",
      "Episode: 216 Total reward: 9.0000 Training loss: 0.4606 Epsilon: 0.0100\n",
      "Episode: 217 Total reward: 9.0000 Training loss: 1.8787 Epsilon: 0.0100\n",
      "Episode: 218 Total reward: 9.0000 Training loss: 1.9759 Epsilon: 0.0100\n",
      "Episode: 219 Total reward: 9.0000 Training loss: 2.4746 Epsilon: 0.0100\n",
      "Episode: 220 Total reward: 11.0000 Training loss: 3.8122 Epsilon: 0.0100\n",
      "Episode: 221 Total reward: 10.0000 Training loss: 2.4628 Epsilon: 0.0100\n",
      "Episode: 222 Total reward: 10.0000 Training loss: 2.7829 Epsilon: 0.0100\n",
      "Episode: 223 Total reward: 8.0000 Training loss: 3.6417 Epsilon: 0.0100\n",
      "Episode: 224 Total reward: 12.0000 Training loss: 1.3605 Epsilon: 0.0100\n",
      "Episode: 225 Total reward: 11.0000 Training loss: 1.4812 Epsilon: 0.0100\n",
      "Episode: 226 Total reward: 11.0000 Training loss: 1.3318 Epsilon: 0.0100\n",
      "Episode: 227 Total reward: 10.0000 Training loss: 11.2863 Epsilon: 0.0100\n",
      "Episode: 228 Total reward: 12.0000 Training loss: 1.0506 Epsilon: 0.0100\n",
      "Episode: 229 Total reward: 10.0000 Training loss: 1.9830 Epsilon: 0.0100\n",
      "Episode: 230 Total reward: 10.0000 Training loss: 7.5153 Epsilon: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 231 Total reward: 10.0000 Training loss: 15.5454 Epsilon: 0.0100\n",
      "Episode: 232 Total reward: 11.0000 Training loss: 3.7806 Epsilon: 0.0100\n",
      "Episode: 233 Total reward: 10.0000 Training loss: 12.9973 Epsilon: 0.0100\n",
      "Episode: 234 Total reward: 9.0000 Training loss: 2.6265 Epsilon: 0.0100\n",
      "Episode: 235 Total reward: 9.0000 Training loss: 2.7579 Epsilon: 0.0100\n",
      "Episode: 236 Total reward: 12.0000 Training loss: 0.8029 Epsilon: 0.0100\n",
      "Episode: 237 Total reward: 12.0000 Training loss: 3.0324 Epsilon: 0.0100\n",
      "Episode: 238 Total reward: 11.0000 Training loss: 1.5601 Epsilon: 0.0100\n",
      "Episode: 239 Total reward: 9.0000 Training loss: 1.3336 Epsilon: 0.0100\n",
      "Episode: 240 Total reward: 14.0000 Training loss: 1.9314 Epsilon: 0.0100\n",
      "Episode: 241 Total reward: 10.0000 Training loss: 12.0199 Epsilon: 0.0100\n",
      "Episode: 242 Total reward: 11.0000 Training loss: 2.3299 Epsilon: 0.0100\n",
      "Episode: 243 Total reward: 9.0000 Training loss: 0.9897 Epsilon: 0.0100\n",
      "Episode: 244 Total reward: 9.0000 Training loss: 1.2217 Epsilon: 0.0100\n",
      "Episode: 245 Total reward: 10.0000 Training loss: 1.4853 Epsilon: 0.0100\n",
      "Episode: 246 Total reward: 11.0000 Training loss: 1.4105 Epsilon: 0.0100\n",
      "Episode: 247 Total reward: 11.0000 Training loss: 3.4865 Epsilon: 0.0100\n",
      "Episode: 248 Total reward: 10.0000 Training loss: 1.5289 Epsilon: 0.0100\n",
      "Episode: 249 Total reward: 11.0000 Training loss: 1.1151 Epsilon: 0.0100\n",
      "Episode: 250 Total reward: 10.0000 Training loss: 1.5049 Epsilon: 0.0100\n",
      "Episode: 251 Total reward: 9.0000 Training loss: 2.1458 Epsilon: 0.0100\n",
      "Episode: 252 Total reward: 11.0000 Training loss: 2.7244 Epsilon: 0.0100\n",
      "Episode: 253 Total reward: 9.0000 Training loss: 1.6568 Epsilon: 0.0100\n",
      "Episode: 254 Total reward: 9.0000 Training loss: 1.4312 Epsilon: 0.0100\n",
      "Episode: 255 Total reward: 10.0000 Training loss: 1.6023 Epsilon: 0.0100\n",
      "Episode: 256 Total reward: 9.0000 Training loss: 1.8765 Epsilon: 0.0100\n",
      "Episode: 257 Total reward: 12.0000 Training loss: 1.6388 Epsilon: 0.0100\n",
      "Episode: 258 Total reward: 10.0000 Training loss: 2.2677 Epsilon: 0.0100\n",
      "Episode: 259 Total reward: 9.0000 Training loss: 1.1510 Epsilon: 0.0100\n",
      "Episode: 260 Total reward: 10.0000 Training loss: 1.4553 Epsilon: 0.0100\n",
      "Episode: 261 Total reward: 10.0000 Training loss: 0.9050 Epsilon: 0.0100\n",
      "Episode: 262 Total reward: 10.0000 Training loss: 1.9888 Epsilon: 0.0100\n",
      "Episode: 263 Total reward: 10.0000 Training loss: 0.7772 Epsilon: 0.0100\n",
      "Episode: 264 Total reward: 13.0000 Training loss: 1.4654 Epsilon: 0.0100\n",
      "Episode: 265 Total reward: 11.0000 Training loss: 1.5626 Epsilon: 0.0100\n",
      "Episode: 266 Total reward: 10.0000 Training loss: 1.6853 Epsilon: 0.0100\n",
      "Episode: 267 Total reward: 10.0000 Training loss: 2.2024 Epsilon: 0.0100\n",
      "Episode: 268 Total reward: 12.0000 Training loss: 1.6180 Epsilon: 0.0100\n",
      "Episode: 269 Total reward: 10.0000 Training loss: 0.9233 Epsilon: 0.0100\n",
      "Episode: 270 Total reward: 12.0000 Training loss: 0.7981 Epsilon: 0.0100\n",
      "Episode: 271 Total reward: 11.0000 Training loss: 1.6892 Epsilon: 0.0100\n",
      "Episode: 272 Total reward: 12.0000 Training loss: 1.9590 Epsilon: 0.0100\n",
      "Episode: 273 Total reward: 10.0000 Training loss: 1.2016 Epsilon: 0.0100\n",
      "Episode: 274 Total reward: 9.0000 Training loss: 1.6566 Epsilon: 0.0100\n",
      "Episode: 275 Total reward: 10.0000 Training loss: 2.5826 Epsilon: 0.0100\n",
      "Episode: 276 Total reward: 13.0000 Training loss: 2.4602 Epsilon: 0.0100\n",
      "Episode: 277 Total reward: 9.0000 Training loss: 0.8150 Epsilon: 0.0100\n",
      "Episode: 278 Total reward: 10.0000 Training loss: 0.3743 Epsilon: 0.0100\n",
      "Episode: 279 Total reward: 10.0000 Training loss: 1.5728 Epsilon: 0.0100\n",
      "Episode: 280 Total reward: 9.0000 Training loss: 3.1953 Epsilon: 0.0100\n",
      "Episode: 281 Total reward: 11.0000 Training loss: 0.7653 Epsilon: 0.0100\n",
      "Episode: 282 Total reward: 12.0000 Training loss: 0.8846 Epsilon: 0.0100\n",
      "Episode: 283 Total reward: 13.0000 Training loss: 1.9192 Epsilon: 0.0100\n",
      "Episode: 284 Total reward: 9.0000 Training loss: 1.9151 Epsilon: 0.0100\n",
      "Episode: 285 Total reward: 10.0000 Training loss: 1.1697 Epsilon: 0.0100\n",
      "Episode: 286 Total reward: 9.0000 Training loss: 1.6769 Epsilon: 0.0100\n",
      "Episode: 287 Total reward: 9.0000 Training loss: 1.9738 Epsilon: 0.0100\n",
      "Episode: 288 Total reward: 8.0000 Training loss: 0.4861 Epsilon: 0.0100\n",
      "Episode: 289 Total reward: 10.0000 Training loss: 4.0672 Epsilon: 0.0100\n",
      "Episode: 290 Total reward: 9.0000 Training loss: 0.7450 Epsilon: 0.0100\n",
      "Episode: 291 Total reward: 10.0000 Training loss: 2.2602 Epsilon: 0.0100\n",
      "Episode: 292 Total reward: 8.0000 Training loss: 1.8424 Epsilon: 0.0100\n",
      "Episode: 293 Total reward: 12.0000 Training loss: 1.4979 Epsilon: 0.0100\n",
      "Episode: 294 Total reward: 9.0000 Training loss: 2.0558 Epsilon: 0.0100\n",
      "Episode: 295 Total reward: 12.0000 Training loss: 3.1772 Epsilon: 0.0100\n",
      "Episode: 296 Total reward: 9.0000 Training loss: 2.3725 Epsilon: 0.0100\n",
      "Episode: 297 Total reward: 11.0000 Training loss: 1.1724 Epsilon: 0.0100\n",
      "Episode: 298 Total reward: 9.0000 Training loss: 1.6433 Epsilon: 0.0100\n",
      "Episode: 299 Total reward: 11.0000 Training loss: 0.5630 Epsilon: 0.0100\n",
      "Episode: 300 Total reward: 11.0000 Training loss: 1.0982 Epsilon: 0.0100\n",
      "Episode: 301 Total reward: 10.0000 Training loss: 1.5856 Epsilon: 0.0100\n",
      "Episode: 302 Total reward: 9.0000 Training loss: 1.0690 Epsilon: 0.0100\n",
      "Episode: 303 Total reward: 11.0000 Training loss: 1.8138 Epsilon: 0.0100\n",
      "Episode: 304 Total reward: 12.0000 Training loss: 1.6893 Epsilon: 0.0100\n",
      "Episode: 305 Total reward: 10.0000 Training loss: 2.5068 Epsilon: 0.0100\n",
      "Episode: 306 Total reward: 10.0000 Training loss: 0.4676 Epsilon: 0.0100\n",
      "Episode: 307 Total reward: 11.0000 Training loss: 1.6247 Epsilon: 0.0100\n",
      "Episode: 308 Total reward: 9.0000 Training loss: 1.8496 Epsilon: 0.0100\n",
      "Episode: 309 Total reward: 11.0000 Training loss: 17.5487 Epsilon: 0.0100\n",
      "Episode: 310 Total reward: 10.0000 Training loss: 2.7436 Epsilon: 0.0100\n",
      "Episode: 311 Total reward: 10.0000 Training loss: 3.0993 Epsilon: 0.0100\n",
      "Episode: 312 Total reward: 9.0000 Training loss: 3.2686 Epsilon: 0.0100\n",
      "Episode: 313 Total reward: 10.0000 Training loss: 18.4563 Epsilon: 0.0100\n",
      "Episode: 314 Total reward: 12.0000 Training loss: 15.2183 Epsilon: 0.0100\n",
      "Episode: 315 Total reward: 13.0000 Training loss: 17.1448 Epsilon: 0.0100\n",
      "Episode: 316 Total reward: 11.0000 Training loss: 0.8874 Epsilon: 0.0100\n",
      "Episode: 317 Total reward: 13.0000 Training loss: 16.8779 Epsilon: 0.0100\n",
      "Episode: 318 Total reward: 9.0000 Training loss: 16.2953 Epsilon: 0.0100\n",
      "Episode: 319 Total reward: 10.0000 Training loss: 1.5128 Epsilon: 0.0100\n",
      "Episode: 320 Total reward: 12.0000 Training loss: 2.7786 Epsilon: 0.0100\n",
      "Episode: 321 Total reward: 12.0000 Training loss: 1.8405 Epsilon: 0.0100\n",
      "Episode: 322 Total reward: 10.0000 Training loss: 0.9143 Epsilon: 0.0100\n",
      "Episode: 323 Total reward: 11.0000 Training loss: 1.7944 Epsilon: 0.0100\n",
      "Episode: 324 Total reward: 11.0000 Training loss: 1.3646 Epsilon: 0.0100\n",
      "Episode: 325 Total reward: 12.0000 Training loss: 1.4078 Epsilon: 0.0100\n",
      "Episode: 326 Total reward: 11.0000 Training loss: 0.7835 Epsilon: 0.0100\n",
      "Episode: 327 Total reward: 10.0000 Training loss: 2.8910 Epsilon: 0.0100\n",
      "Episode: 328 Total reward: 12.0000 Training loss: 1.5801 Epsilon: 0.0100\n",
      "Episode: 329 Total reward: 11.0000 Training loss: 17.4445 Epsilon: 0.0100\n",
      "Episode: 330 Total reward: 9.0000 Training loss: 2.6093 Epsilon: 0.0100\n",
      "Episode: 331 Total reward: 11.0000 Training loss: 29.9192 Epsilon: 0.0100\n",
      "Episode: 332 Total reward: 12.0000 Training loss: 1.5531 Epsilon: 0.0100\n",
      "Episode: 333 Total reward: 11.0000 Training loss: 1.5970 Epsilon: 0.0100\n",
      "Episode: 334 Total reward: 12.0000 Training loss: 1.2355 Epsilon: 0.0100\n",
      "Episode: 335 Total reward: 10.0000 Training loss: 1.6157 Epsilon: 0.0100\n",
      "Episode: 336 Total reward: 12.0000 Training loss: 0.4650 Epsilon: 0.0100\n",
      "Episode: 337 Total reward: 12.0000 Training loss: 0.9162 Epsilon: 0.0100\n",
      "Episode: 338 Total reward: 9.0000 Training loss: 2.9292 Epsilon: 0.0100\n",
      "Episode: 339 Total reward: 10.0000 Training loss: 2.7586 Epsilon: 0.0100\n",
      "Episode: 340 Total reward: 11.0000 Training loss: 0.7898 Epsilon: 0.0100\n",
      "Episode: 341 Total reward: 9.0000 Training loss: 15.8620 Epsilon: 0.0100\n",
      "Episode: 342 Total reward: 12.0000 Training loss: 0.3969 Epsilon: 0.0100\n",
      "Episode: 343 Total reward: 11.0000 Training loss: 1.7953 Epsilon: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 344 Total reward: 9.0000 Training loss: 1.2946 Epsilon: 0.0100\n",
      "Episode: 345 Total reward: 11.0000 Training loss: 16.6062 Epsilon: 0.0100\n",
      "Episode: 346 Total reward: 11.0000 Training loss: 15.9667 Epsilon: 0.0100\n",
      "Episode: 347 Total reward: 9.0000 Training loss: 4.4652 Epsilon: 0.0100\n",
      "Episode: 348 Total reward: 12.0000 Training loss: 3.0105 Epsilon: 0.0100\n",
      "Episode: 349 Total reward: 12.0000 Training loss: 2.5726 Epsilon: 0.0100\n",
      "Episode: 350 Total reward: 13.0000 Training loss: 0.4930 Epsilon: 0.0100\n",
      "Episode: 351 Total reward: 12.0000 Training loss: 1.1700 Epsilon: 0.0100\n",
      "Episode: 352 Total reward: 11.0000 Training loss: 0.7346 Epsilon: 0.0100\n",
      "Episode: 353 Total reward: 11.0000 Training loss: 2.7020 Epsilon: 0.0100\n",
      "Episode: 354 Total reward: 9.0000 Training loss: 1.7156 Epsilon: 0.0100\n",
      "Episode: 355 Total reward: 12.0000 Training loss: 16.3007 Epsilon: 0.0100\n",
      "Episode: 356 Total reward: 12.0000 Training loss: 1.5773 Epsilon: 0.0100\n",
      "Episode: 357 Total reward: 12.0000 Training loss: 0.7358 Epsilon: 0.0100\n",
      "Episode: 358 Total reward: 9.0000 Training loss: 1.6706 Epsilon: 0.0100\n",
      "Episode: 359 Total reward: 13.0000 Training loss: 2.1833 Epsilon: 0.0100\n",
      "Episode: 360 Total reward: 13.0000 Training loss: 1.2131 Epsilon: 0.0100\n",
      "Episode: 361 Total reward: 11.0000 Training loss: 1.4052 Epsilon: 0.0100\n",
      "Episode: 362 Total reward: 10.0000 Training loss: 1.2932 Epsilon: 0.0100\n",
      "Episode: 363 Total reward: 10.0000 Training loss: 3.4929 Epsilon: 0.0100\n",
      "Episode: 364 Total reward: 10.0000 Training loss: 1.4372 Epsilon: 0.0100\n",
      "Episode: 365 Total reward: 11.0000 Training loss: 2.5283 Epsilon: 0.0100\n",
      "Episode: 366 Total reward: 13.0000 Training loss: 1.5045 Epsilon: 0.0100\n",
      "Episode: 367 Total reward: 11.0000 Training loss: 1.0529 Epsilon: 0.0100\n",
      "Episode: 368 Total reward: 11.0000 Training loss: 1.7750 Epsilon: 0.0100\n",
      "Episode: 369 Total reward: 11.0000 Training loss: 0.6906 Epsilon: 0.0100\n",
      "Episode: 370 Total reward: 12.0000 Training loss: 9.7781 Epsilon: 0.0100\n",
      "Episode: 371 Total reward: 11.0000 Training loss: 2.0284 Epsilon: 0.0100\n",
      "Episode: 372 Total reward: 10.0000 Training loss: 0.4261 Epsilon: 0.0100\n",
      "Episode: 373 Total reward: 13.0000 Training loss: 1.3367 Epsilon: 0.0100\n",
      "Episode: 374 Total reward: 10.0000 Training loss: 1.2205 Epsilon: 0.0100\n",
      "Episode: 375 Total reward: 13.0000 Training loss: 2.2250 Epsilon: 0.0100\n",
      "Episode: 376 Total reward: 12.0000 Training loss: 3.3058 Epsilon: 0.0100\n",
      "Episode: 377 Total reward: 13.0000 Training loss: 0.4652 Epsilon: 0.0100\n",
      "Episode: 378 Total reward: 14.0000 Training loss: 7.9129 Epsilon: 0.0100\n",
      "Episode: 379 Total reward: 12.0000 Training loss: 1.4956 Epsilon: 0.0100\n",
      "Episode: 380 Total reward: 15.0000 Training loss: 1.5486 Epsilon: 0.0100\n",
      "Episode: 381 Total reward: 12.0000 Training loss: 1.9277 Epsilon: 0.0100\n",
      "Episode: 382 Total reward: 13.0000 Training loss: 2.0550 Epsilon: 0.0100\n",
      "Episode: 383 Total reward: 12.0000 Training loss: 3.1188 Epsilon: 0.0100\n",
      "Episode: 384 Total reward: 15.0000 Training loss: 1.0782 Epsilon: 0.0100\n",
      "Episode: 385 Total reward: 10.0000 Training loss: 2.3302 Epsilon: 0.0100\n",
      "Episode: 386 Total reward: 9.0000 Training loss: 1.7997 Epsilon: 0.0100\n",
      "Episode: 387 Total reward: 9.0000 Training loss: 3.0127 Epsilon: 0.0100\n",
      "Episode: 388 Total reward: 16.0000 Training loss: 0.8067 Epsilon: 0.0100\n",
      "Episode: 389 Total reward: 12.0000 Training loss: 2.0301 Epsilon: 0.0100\n",
      "Episode: 390 Total reward: 14.0000 Training loss: 2.4013 Epsilon: 0.0100\n",
      "Episode: 391 Total reward: 13.0000 Training loss: 1.6306 Epsilon: 0.0100\n",
      "Episode: 392 Total reward: 14.0000 Training loss: 14.0470 Epsilon: 0.0100\n",
      "Episode: 393 Total reward: 12.0000 Training loss: 1.0518 Epsilon: 0.0100\n",
      "Episode: 394 Total reward: 10.0000 Training loss: 3.7032 Epsilon: 0.0100\n",
      "Episode: 395 Total reward: 14.0000 Training loss: 2.3499 Epsilon: 0.0100\n",
      "Episode: 396 Total reward: 13.0000 Training loss: 1.0772 Epsilon: 0.0100\n",
      "Episode: 397 Total reward: 12.0000 Training loss: 0.6783 Epsilon: 0.0100\n",
      "Episode: 398 Total reward: 13.0000 Training loss: 2.6408 Epsilon: 0.0100\n",
      "Episode: 399 Total reward: 10.0000 Training loss: 3.8885 Epsilon: 0.0100\n",
      "Episode: 400 Total reward: 10.0000 Training loss: 1.6920 Epsilon: 0.0100\n",
      "Episode: 401 Total reward: 11.0000 Training loss: 10.4146 Epsilon: 0.0100\n",
      "Episode: 402 Total reward: 10.0000 Training loss: 2.0605 Epsilon: 0.0100\n",
      "Episode: 403 Total reward: 13.0000 Training loss: 12.6083 Epsilon: 0.0100\n",
      "Episode: 404 Total reward: 12.0000 Training loss: 10.2274 Epsilon: 0.0100\n",
      "Episode: 405 Total reward: 13.0000 Training loss: 3.5129 Epsilon: 0.0100\n",
      "Episode: 406 Total reward: 11.0000 Training loss: 1.9415 Epsilon: 0.0100\n",
      "Episode: 407 Total reward: 12.0000 Training loss: 1.4517 Epsilon: 0.0100\n",
      "Episode: 408 Total reward: 12.0000 Training loss: 1.1408 Epsilon: 0.0100\n",
      "Episode: 409 Total reward: 11.0000 Training loss: 1.9687 Epsilon: 0.0100\n",
      "Episode: 410 Total reward: 13.0000 Training loss: 1.9680 Epsilon: 0.0100\n",
      "Episode: 411 Total reward: 14.0000 Training loss: 2.3652 Epsilon: 0.0100\n",
      "Episode: 412 Total reward: 13.0000 Training loss: 2.8418 Epsilon: 0.0100\n",
      "Episode: 413 Total reward: 10.0000 Training loss: 0.4891 Epsilon: 0.0100\n",
      "Episode: 414 Total reward: 10.0000 Training loss: 0.7588 Epsilon: 0.0100\n",
      "Episode: 415 Total reward: 11.0000 Training loss: 2.9348 Epsilon: 0.0100\n",
      "Episode: 416 Total reward: 10.0000 Training loss: 3.0543 Epsilon: 0.0100\n",
      "Episode: 417 Total reward: 12.0000 Training loss: 3.5847 Epsilon: 0.0100\n",
      "Episode: 418 Total reward: 13.0000 Training loss: 0.8836 Epsilon: 0.0100\n",
      "Episode: 419 Total reward: 12.0000 Training loss: 1.9862 Epsilon: 0.0100\n",
      "Episode: 420 Total reward: 13.0000 Training loss: 10.3895 Epsilon: 0.0100\n",
      "Episode: 421 Total reward: 13.0000 Training loss: 1.9310 Epsilon: 0.0100\n",
      "Episode: 422 Total reward: 13.0000 Training loss: 2.0303 Epsilon: 0.0100\n",
      "Episode: 423 Total reward: 13.0000 Training loss: 1.6397 Epsilon: 0.0100\n",
      "Episode: 424 Total reward: 11.0000 Training loss: 2.6946 Epsilon: 0.0100\n",
      "Episode: 425 Total reward: 11.0000 Training loss: 3.5278 Epsilon: 0.0100\n",
      "Episode: 426 Total reward: 13.0000 Training loss: 3.0843 Epsilon: 0.0100\n",
      "Episode: 427 Total reward: 14.0000 Training loss: 5.1312 Epsilon: 0.0100\n",
      "Episode: 428 Total reward: 10.0000 Training loss: 1.6727 Epsilon: 0.0100\n",
      "Episode: 429 Total reward: 11.0000 Training loss: 2.0763 Epsilon: 0.0100\n",
      "Episode: 430 Total reward: 11.0000 Training loss: 10.7529 Epsilon: 0.0100\n",
      "Episode: 431 Total reward: 11.0000 Training loss: 2.0158 Epsilon: 0.0100\n",
      "Episode: 432 Total reward: 12.0000 Training loss: 10.4016 Epsilon: 0.0100\n",
      "Episode: 433 Total reward: 10.0000 Training loss: 3.0237 Epsilon: 0.0100\n",
      "Episode: 434 Total reward: 12.0000 Training loss: 10.8215 Epsilon: 0.0100\n",
      "Episode: 435 Total reward: 12.0000 Training loss: 0.3882 Epsilon: 0.0100\n",
      "Episode: 436 Total reward: 12.0000 Training loss: 10.1524 Epsilon: 0.0100\n",
      "Episode: 437 Total reward: 11.0000 Training loss: 2.2618 Epsilon: 0.0100\n",
      "Episode: 438 Total reward: 12.0000 Training loss: 1.2888 Epsilon: 0.0100\n",
      "Episode: 439 Total reward: 12.0000 Training loss: 1.2355 Epsilon: 0.0100\n",
      "Episode: 440 Total reward: 10.0000 Training loss: 1.5542 Epsilon: 0.0100\n",
      "Episode: 441 Total reward: 13.0000 Training loss: 0.8946 Epsilon: 0.0100\n",
      "Episode: 442 Total reward: 14.0000 Training loss: 2.8658 Epsilon: 0.0100\n",
      "Episode: 443 Total reward: 14.0000 Training loss: 1.7825 Epsilon: 0.0100\n",
      "Episode: 444 Total reward: 12.0000 Training loss: 1.5617 Epsilon: 0.0100\n",
      "Episode: 445 Total reward: 11.0000 Training loss: 0.4242 Epsilon: 0.0100\n",
      "Episode: 446 Total reward: 13.0000 Training loss: 1.4021 Epsilon: 0.0100\n",
      "Episode: 447 Total reward: 15.0000 Training loss: 1.4190 Epsilon: 0.0100\n",
      "Episode: 448 Total reward: 11.0000 Training loss: 2.1881 Epsilon: 0.0100\n",
      "Episode: 449 Total reward: 11.0000 Training loss: 2.1928 Epsilon: 0.0100\n",
      "Episode: 450 Total reward: 14.0000 Training loss: 1.5666 Epsilon: 0.0100\n",
      "Episode: 451 Total reward: 12.0000 Training loss: 0.8890 Epsilon: 0.0100\n",
      "Episode: 452 Total reward: 13.0000 Training loss: 4.6934 Epsilon: 0.0100\n",
      "Episode: 453 Total reward: 12.0000 Training loss: 3.1005 Epsilon: 0.0100\n",
      "Episode: 454 Total reward: 13.0000 Training loss: 2.4939 Epsilon: 0.0100\n",
      "Episode: 455 Total reward: 10.0000 Training loss: 9.9425 Epsilon: 0.0100\n",
      "Episode: 456 Total reward: 12.0000 Training loss: 11.4453 Epsilon: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 457 Total reward: 13.0000 Training loss: 2.5662 Epsilon: 0.0100\n",
      "Episode: 458 Total reward: 14.0000 Training loss: 2.2803 Epsilon: 0.0100\n",
      "Episode: 459 Total reward: 14.0000 Training loss: 11.8071 Epsilon: 0.0100\n",
      "Episode: 460 Total reward: 12.0000 Training loss: 2.3418 Epsilon: 0.0100\n",
      "Episode: 461 Total reward: 12.0000 Training loss: 1.6713 Epsilon: 0.0100\n",
      "Episode: 462 Total reward: 12.0000 Training loss: 1.6766 Epsilon: 0.0100\n",
      "Episode: 463 Total reward: 14.0000 Training loss: 3.7475 Epsilon: 0.0100\n",
      "Episode: 464 Total reward: 14.0000 Training loss: 12.1081 Epsilon: 0.0100\n",
      "Episode: 465 Total reward: 13.0000 Training loss: 3.1842 Epsilon: 0.0100\n",
      "Episode: 466 Total reward: 12.0000 Training loss: 11.2827 Epsilon: 0.0100\n",
      "Episode: 467 Total reward: 12.0000 Training loss: 1.7380 Epsilon: 0.0100\n",
      "Episode: 468 Total reward: 12.0000 Training loss: 1.9025 Epsilon: 0.0100\n",
      "Episode: 469 Total reward: 15.0000 Training loss: 2.9771 Epsilon: 0.0100\n",
      "Episode: 470 Total reward: 12.0000 Training loss: 1.7954 Epsilon: 0.0100\n",
      "Episode: 471 Total reward: 12.0000 Training loss: 1.3952 Epsilon: 0.0100\n",
      "Episode: 472 Total reward: 11.0000 Training loss: 1.1913 Epsilon: 0.0100\n",
      "Episode: 473 Total reward: 13.0000 Training loss: 2.3650 Epsilon: 0.0100\n",
      "Episode: 474 Total reward: 15.0000 Training loss: 2.8729 Epsilon: 0.0100\n",
      "Episode: 475 Total reward: 14.0000 Training loss: 1.8446 Epsilon: 0.0100\n",
      "Episode: 476 Total reward: 13.0000 Training loss: 1.9392 Epsilon: 0.0100\n",
      "Episode: 477 Total reward: 17.0000 Training loss: 0.5238 Epsilon: 0.0100\n",
      "Episode: 478 Total reward: 16.0000 Training loss: 2.5678 Epsilon: 0.0100\n",
      "Episode: 479 Total reward: 13.0000 Training loss: 9.5369 Epsilon: 0.0100\n",
      "Episode: 480 Total reward: 66.0000 Training loss: 4.5374 Epsilon: 0.0100\n",
      "Episode: 481 Total reward: 13.0000 Training loss: 4.5856 Epsilon: 0.0100\n",
      "Episode: 482 Total reward: 11.0000 Training loss: 2.6822 Epsilon: 0.0100\n",
      "Episode: 483 Total reward: 13.0000 Training loss: 2.8573 Epsilon: 0.0100\n",
      "Episode: 484 Total reward: 12.0000 Training loss: 2.2160 Epsilon: 0.0100\n",
      "Episode: 485 Total reward: 12.0000 Training loss: 13.1141 Epsilon: 0.0100\n",
      "Episode: 486 Total reward: 15.0000 Training loss: 1.0639 Epsilon: 0.0100\n",
      "Episode: 487 Total reward: 13.0000 Training loss: 0.8756 Epsilon: 0.0100\n",
      "Episode: 488 Total reward: 13.0000 Training loss: 2.4232 Epsilon: 0.0100\n",
      "Episode: 489 Total reward: 12.0000 Training loss: 3.1809 Epsilon: 0.0100\n",
      "Episode: 490 Total reward: 54.0000 Training loss: 1.9020 Epsilon: 0.0100\n",
      "Episode: 491 Total reward: 74.0000 Training loss: 1.6714 Epsilon: 0.0100\n",
      "Episode: 492 Total reward: 37.0000 Training loss: 20.8372 Epsilon: 0.0100\n",
      "Episode: 493 Total reward: 89.0000 Training loss: 2.4275 Epsilon: 0.0100\n",
      "Episode: 494 Total reward: 40.0000 Training loss: 0.8216 Epsilon: 0.0100\n",
      "Episode: 495 Total reward: 14.0000 Training loss: 1.3094 Epsilon: 0.0100\n",
      "Episode: 496 Total reward: 35.0000 Training loss: 0.5308 Epsilon: 0.0100\n",
      "Episode: 497 Total reward: 117.0000 Training loss: 2.6971 Epsilon: 0.0100\n",
      "Episode: 498 Total reward: 34.0000 Training loss: 11.9527 Epsilon: 0.0100\n",
      "Episode: 499 Total reward: 96.0000 Training loss: 2.4424 Epsilon: 0.0100\n",
      "Episode: 500 Total reward: 200.0000 Training loss: 2.6106 Epsilon: 0.0100\n"
     ]
    }
   ],
   "source": [
    "def train_agent():\n",
    "    # Intantiate memory and populate\n",
    "    exp_replay = Memory_exp_replay(memory_size)\n",
    "    exp_replay = populate_memory(env, exp_replay, batch_size_Q)\n",
    "\n",
    "    # Initiliaze TensorFlow Graph\n",
    "    tf.reset_default_graph()\n",
    "    Q_NN_1 = NN_Q_approx(learning_rate=learning_rate_nn, hidden_size=hidden_size, state_space=state_space, action_space=action_space, name='Q_action_target')\n",
    "    Q_NN_2 = NN_Q_approx(learning_rate=learning_rate_nn, hidden_size=hidden_size, state_space=state_space, action_space=action_space, name='Q_action_grad')\n",
    "    nns = [Q_NN_1, Q_NN_2]\n",
    "\n",
    "\n",
    "    training_rewards = list()\n",
    "    training_loss = list()\n",
    "    with tf.Session() as sess:\n",
    "        # Initializa variables \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ep_iter = 0\n",
    "\n",
    "        for i in range(1, max_episodes+1):\n",
    "            # Intiliazing variables for episode.\n",
    "            s_t1 = env.reset()\n",
    "            time_step = 0\n",
    "            episode_reward = 0\n",
    "\n",
    "            while time_step < max_steps_episode:\n",
    "                # Watch it learn.\n",
    "                # env.render()\n",
    "\n",
    "                nn_ind = int(np.random.choice(a=2, size=1))\n",
    "                action_nn = nns[nn_ind]\n",
    "                target_nn = nns[not(nn_ind)]\n",
    "\n",
    "                s_t = s_t1\n",
    "                # Controling epsilon.\n",
    "                ep_iter += 1\n",
    "                epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*i) \n",
    "\n",
    "                # Find Q Values and select action under E-greedy policy.\n",
    "                q_values = sess.run(action_nn.output, feed_dict={action_nn.inputs:np.array(s_t).reshape((1, -1))})\n",
    "                a_t = epsilon_greedy(epsilon, q_values)\n",
    "\n",
    "                s_t1, r_t1, done, info = env.step(a_t)\n",
    "\n",
    "                episode_reward += gamma*r_t1\n",
    "                time_step += 1\n",
    "\n",
    "                if done:\n",
    "                    # Terminating episode\n",
    "                    time_step = max_steps_episode\n",
    "                    s_t1 = np.zeros(state_space)\n",
    "                    # Update memory\n",
    "                    exp_replay.add_timestep((s_t, a_t, r_t1, s_t1))\n",
    "\n",
    "                    # Tracking information\n",
    "                    training_rewards.append((i, episode_reward))\n",
    "                    training_loss.append((i, loss))\n",
    "                    print('Episode: {}'.format(i),\n",
    "\n",
    "\n",
    "                          'Total reward: {:.4f}'.format(episode_reward),\n",
    "                          'Training loss: {:.4f}'.format(loss),\n",
    "                          'Epsilon: {:.4f}'.format(epsilon))\n",
    "                else:\n",
    "                    # Update memory\n",
    "                    exp_replay.add_timestep((s_t, a_t, r_t1, s_t1))\n",
    "\n",
    "                # Train network.\n",
    "                states, actions, rewards, next_states = exp_replay.sample_random(batch_size_Q)\n",
    "\n",
    "                estimated_Qs = sess.run(target_nn.output, feed_dict = {target_nn.inputs:next_states})\n",
    "                action_Qs = sess.run(action_nn.output, feed_dict = {action_nn.inputs:next_states})\n",
    "                found_initial = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "                estimated_Qs[found_initial] = np.zeros(estimated_Qs[0].shape)\n",
    "                action_Qs[found_initial] = np.zeros(estimated_Qs[0].shape)\n",
    "                actions_t = (action_Qs==np.amax(action_Qs, axis=1, keepdims=True))\n",
    "\n",
    "                target_Qs = rewards + gamma*np.max(estimated_Qs*actions_t, axis=1)\n",
    "\n",
    "                feed_dict = {action_nn.inputs:states, action_nn.actions:actions, action_nn.target_Q: target_Qs}\n",
    "                loss, _ = sess.run([action_nn.loss, action_nn.opt], feed_dict)\n",
    "\n",
    "                if (len(training_rewards)>=100) and (np.array(training_rewards[-100:])>= 195).all():\n",
    "                    print('Gym solved!')\n",
    "                    print('Final Episode:', i)\n",
    "                    return training_loss, training_rewards\n",
    "training_loss, training_rewards = train_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
